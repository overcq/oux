//-*-C-*-
/*******************************************************************************
*   ___   publicplace
*  ¦OUX¦  C+
*  ¦/C+¦  component
*   ---   base
*         memory blocks manager
* ©overcq                on ‟Gentoo Linux 13.0” “x86_64”             2015‒4‒28 *
*******************************************************************************/
/* Menedżer bloków pamięci alokowanej dynamicznie, ale nie do niepotrzebnego alokowania i zwalniania w pętlach, przechowujący rozmiar pojedynczego elementu bloku tylko do własnej administracji pamięcią.
Implementacyjnie – w “E_mem_Q_blk” uchwytami są adresy elementów (ponad zmienianymi numerami elementów), a w “E_mem_Q_tab” – numery elementów (ponad zmienianymi adresami). Czyli w sensie funkcjonalnym z zewnątrz – ten pierwszy jest menedżerem tablic rzeczywistych (ciągłych w pamięci), a ten drugi – zarządzanych.
⁂
Deterministyczna strategia modyfikacji pamięci stosowana w tym menedżerze i globalnie wewnętrznie w miejscu użycia jego funkcji.
Struktura osadzenia przepływu wykonania menedżera:
⁃ W punkcie wejścia oraz wyjścia przepływu wykonania ‹zadania› z funkcji menedżera stan pamięci zarządzanej jest integralny. Funkcja może zmienić adres tylko tego bloku pamięci spośród udostępnionych przez menedżera, względem którego została wywołana.
⁃ W trakcie posiadania przepływu wykonania przez menedżera może wystąpić przerwanie zabierające przepływ wykonania — w postaci “sygnału” ‘uniksowego’, którego procedura obsługi może ewentualnie wykonywać dostęp do bloku pamięci zarządzanego przez tego menedżera; teksty procedur obsługi są w “menedżerze przepływu wykonania”.
⁃ Jednak “sygnały” ‘uniksowe’ czytające lub zmieniające konkretne bloki pamięci są blokowane przed przejęciem przepływu wykonania podczas ich modyfikacji, ponieważ te konkretne bloki są używane poprzez któregoś menedżera ·struktur· pamięci (menedżera pamięci wyższego poziomu), który nie potrafiłby wykonać swoich funkcji “atomowo” ze względu na złożoność danych, więc “sygnał” ‘uniksowy’ nie wystąpi podczas zmiany adresu bloku pamięci, z którego korzysta.
⁃ Jakkolwiek “sygnał” ‘uniksowy’ “SEGV” używany nie jako błąd — do automatycznego ‘doalokowywania’ stron pamięci “stosów” ‹zadań› z wcześniej zarezerwowanego obszaru przestrzeni adresowej — może wystąpić kiedykolwiek po przesunięciu niżej wierzchołka “stosu” ‹zadania› w procedurze tego menedżera przez ‘kompilator’, a procedura obsługi tego “sygnału” czyta i zmienia dane w tablicy ‹zadań›. Więc w konkretnej implementacji zmieniania tablicy ‹zadań› “stos” ‹zadania› jest ‘prealokowany’ (“E_flow_Q_task_I_touch_stack”), a dla innego “thread” – ustawiany “mutex” oraz ‹przełącznik› zabraniający czytania tej tablicy w procedurze obsługi “sygnału” “SEGV”.
Struktura “atomowości” menedżera:
⁃ W tekście programu menedżera jest gwarantowane ‘implicite’ ze składni języka (tzn. z domyślnej alokacji zmiennych lokalnych na “stosie” ·przed ich użyciem· jako wartość wyrażenia przypisywanego), że wpis w tablicy systemowej menedżera (adres, rozmiar bloku) zostanie zmieniony “atomowo” względem poszczególnego elementu wpisu (adres lub rozmiar), oraz z linii programu – zawsze tak, by przed i po “atomowej” zmianie odczyt całego wpisu był poprawny względem chwilowo obecnego bloku pamięci z zawartością. To umożliwia przerwanie przepływu wykonania przez “sygnał” lub “wątek” systemu operacyjnego i poprawny dostęp do pamięci udostępnionej przez menedżera, ale nie wywołanie funkcji menedżera. (Czy to ma jakieś zastosowanie, gdy funkcje i tak muszą być blokowane?)
⁃ Pomiędzy wszystkimi tablicami systemowymi menedżera integralność jest zachowywana przez realizację właściwej sekwencji zmieniania wpisów, w których to sekwencjach blok pamięci jest utrzymywany w pierwszej funkcji na nim się wykonującej— przez utrzymywanie jego wpisu w zmiennych lokalnych, a usuniętego z tablicy wolnych bloków, niedostępnego dla kolejnych funkcji. (Kolejność zmian “atomowych” dla chwilowej poprawności w trakcie zmiany pojedynczego wpisu nie została jeszcze sprawdzona.) To umożliwia rekurencyjne wywoływanie uniwersalnych funkcji wewnętrz menedżera oraz po dodaniu odpowiednich instrukcji synchronizacji “międzywątkowych” umożliwi przerywanie przepływu wykonania menedżera przez system operacyjny “wywłaszczający” dla kolejnego “wątku” spośród tych (nie synchronizowanych w “menedżerze przepływu wykonania”) nałożonych na program w technologii ‟oux” wymaganiami którejś ‘dokompilowanej’ “biblioteki”— i wykonanie funkcji menedżera przez program “biblioteczny” (np. zastąpionej procedury “biblioteki” ‟C”: “malloc”, “calloc”, “realloc”, “free”).
⁃ Natomiast kopiowanie zawartości bloku pamięci podczas ‘realokacji’ obejmujące zwalnianie pamięci odrazu do systemu operacyjnego lub obszary zachodzące musi być realizowane tak, by nie nastąpiło przerwanie, a w szczególności– przez “SIGSEGV”.
⁂
Można alokować zero jednostek pamięci: ‘alokowany’ jest symboliczny adres będący małą liczbą, traktowany tak samo jak adres rzeczywisty.
Parametry podawane do funkcji nie mogą oznaczać pustych operacji; jest to wymagane dla niewyjścia poza integralność programu.
Funkcje podają “0” przy braku możliwosci ‘alokacji’ nowej pamięci, a przy nieznalezieniu wpisu w rejestrze ‘alokowanych’ bloków generują ‹niepowodzenie zakańczające›.
Musi być zagwarantowana obecność co najmniej jednego wpisu w tablicach systemowych.
⁂
Zależnie od zastosowania powiększania bloku pamięci, w celu niewykonywania niepotrzebnych instrukcji należy wybrać pierwszą funkcję w kolejności: “add” (nie zależy, gdzie dodane), “prepend_append”, “append”, “prepend”, “insert” (gdy musi być konkretne miejsce).
*/
//------------------------------------------------------------------------------
//TODO mapped free
//TODO Funkcje “move” oprócz obecnych “copy”, by można było w nich użyć “remap”, jeśli jest dostępne.
// Zaimplementować ‘alokacje’ sfragmentowane (listy bloków ‘alokowanego’) i optymalizacje przy braku pamieci z projektowanego kiedyś menedżera pamięci (“mem_mng– use”).
//==============================================================================
    #ifdef C_pthreads
#define _single_thread_begin    Vr_( pthread_mutex_lock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex ))
#define _single_thread_end      Vr_( pthread_mutex_unlock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex ))
    #else
#define _single_thread_begin
#define _single_thread_end
    #endif
//------------------------------------------------------------------------------
#define E_mem_Q_blk_S_align_to_all  alignof(max_align_t)
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
struct E_mem_Q_blk_Z_mapped // Obszary stron pamięci otrzymane z systemu operacyjnego.
{ Pc p; // “0” tutaj i w “l” oznacza pusty wpis; ale wystarczy sprawdzić jedno.
  N l;
};
struct E_mem_Q_blk_Z_free // Dla optymalizacji wyszukiwania obszaru nowej ‘alokacji’.
{ Pc p; // “0” tutaj i w “l” oznacza pusty wpis; ale wystarczy sprawdzić jedno.
  N l;
};
struct E_mem_Q_blk_Z_allocated // Dla kontroli poprawności wydawania i oddawania ‘alokacji’.
{ Pc p; // “0” oznacza pusty wpis.
  N n; // W niepustym wpisie — “0” oznacza ‛zerowy wpis’.
  N u; // ‘unit’
};
//==============================================================================
    #ifdef E_mem_Q_blk_C_debug
_internal
void
E_mem_Q_blk_I_print( N line
){  struct E_mem_Q_blk_Z_mapped *mapped_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p;
    for_n( i, E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].n )
    {   G_(); Gd(i); Gh( mapped_p[i].p ); Gh( mapped_p[i].p + mapped_p[i].l );
    }
    struct E_mem_Q_blk_Z_allocated *allocated_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p;
    for_n_( i, E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].n )
    {   G_(); Gd(i); Gh( allocated_p[i].p ); Gh( allocated_p[i].p + allocated_p[i].u * allocated_p[i].n );
    }
    struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
    for_n_( i, E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n )
    {   G_(); Gd(i); Gh( free_p[i].p ); Gh( free_p[i].p + free_p[i].l );
    }
    G_(); Gd(line);
}
_internal
B
E_mem_Q_blk_T_new_0( P p
){  Pc p_end;
    V1p_( p_end = sbrk(0) );
    return (Pc)p < p_end;
}
_internal
void
E_mem_Q_blk_I_assert_on_return( N line
){  struct E_mem_Q_blk_Z_mapped *mapped_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p;
    struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
    struct E_mem_Q_blk_Z_allocated *allocated_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p;
    N mapped_n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].n;
    N free_n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n;
    N allocated_n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].n;
    for_n_rev( i, mapped_n )
        if( mapped_p[i].p )
            break;
    if( ~i )
        while( i-- )
        {   if( !mapped_p[i].p )
            {   E_mem_Q_blk_I_print(line);
                G_(); Gd(i); V(); // empty value inside
            }
        }
    Pc p = 0;
    for_n_( i, mapped_n )
    {   if( !mapped_p[i].p )
            break;
        if( p >= mapped_p[i].p )
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // not sorted or duplicate address
        }
        p = mapped_p[i].p;
    }
    for_n_rev_( i, allocated_n )
        if( allocated_p[i].p )
            break;
    if( ~i )
        while( i-- )
            if( !allocated_p[i].p )
            {   E_mem_Q_blk_I_print(line);
                G_(); Gd(i); V(); // empty value inside
            }
    p = 0;
    for_n_( i, allocated_n )
    {   if( !allocated_p[i].p )
            break;
        if( p >= allocated_p[i].p )
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // not sorted or duplicate address
        }
        p = allocated_p[i].p;
    }
    for_n_( i, allocated_n )
    {   if( !allocated_p[i].p )
            break;
        if( allocated_p[i].n )
        {   i++;
            break;
        }
    }
    for( ; i != allocated_n; i++ )
    {   if( !allocated_p[i].p )
            break;
        if( !allocated_p[i].n )
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // 0‐size after other‐size entry
        }
    }
    for_n_rev_( i, free_n )
        if( free_p[i].p )
            break;
    if( ~i )
        while( i-- )
            if( !free_p[i].p )
            {   E_mem_Q_blk_I_print(line);
                G_(); Gd(i); V(); // empty value inside
            }
    p = 0;
    for_n_( i, free_n )
    {   if( !free_p[i].p )
            break;
        if( p >= free_p[i].p )
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // not sorted or duplicate address
        }
        p = free_p[i].p;
    }
    for_n_( i, free_n )
    {   if(( !free_p[i].p
          && free_p[i].l
        )
        || ( free_p[i].p
          && !free_p[i].l
        ))
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // inconsistent
        }
    }
    for_n_( i, mapped_n )
    {   if(( !mapped_p[i].p
          && mapped_p[i].l
        )
        || ( mapped_p[i].p
          && !mapped_p[i].l
        ))
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V(); // inconsistent
        }
        if( !mapped_p[i].p )
            break;
        if( !E_simple_Z_p_T_aligned_to_v2( mapped_p[i].p, E_base_S->E_mem_S_page_size ))
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V();
        }
        if( !E_simple_Z_n_T_aligned_to_v2( mapped_p[i].l, E_base_S->E_mem_S_page_size ))
        {   E_mem_Q_blk_I_print(line);
            G_(); Gd(i); V();
        }
    }
    for_n( allocated_i, allocated_n )
    {   if( !allocated_p[ allocated_i ].p
        || allocated_p[ allocated_i ].n
        )
            break;
    }
        #ifndef C_to_libs_C_replace_c_alloc_S_libc_filename
    N free_i = 0;
    for_n( mapped_i, mapped_n )
    {   if( !mapped_p[ mapped_i ].p )
            break;
        Pc p = mapped_p[ mapped_i ].p;
        if( free_i != free_n
        && free_p[ free_i ].p
        && p == free_p[ free_i ].p
        )
        {   p += free_p[ free_i ].l;
            free_i++;
        }
        do
        {   while( allocated_i != allocated_n
            && allocated_p[ allocated_i ].p
            && p == allocated_p[ allocated_i ].p
            )
            {   p += allocated_p[ allocated_i ].n * allocated_p[ allocated_i ].u;
                allocated_i++;
            }
            if( p != mapped_p[ mapped_i ].p + mapped_p[ mapped_i ].l )
            {   if( free_i != free_n
                && free_p[ free_i ].p
                && p == free_p[ free_i ].p
                )
                {   p += free_p[ free_i ].l;
                    free_i++;
                }else
                {   E_mem_Q_blk_I_print(line);
                    G_(); Gh(p); V(); // linearity
                }
            }
        }while( p < mapped_p[ mapped_i ].p + mapped_p[ mapped_i ].l
        && allocated_i != allocated_n
        && allocated_p[ allocated_i ].p
        );
        if( p != mapped_p[ mapped_i ].p + mapped_p[ mapped_i ].l )
        {   E_mem_Q_blk_I_print(line);
            G_(); Gh(p); V(); // linearity
        }
    }
    if( allocated_i != allocated_n
    && allocated_p[ allocated_i ].p
    )
    {   G_(); Gd(line); Gh( allocated_p[ allocated_i ].p ); V(); // lost
    }
    if( free_i != free_n
    && free_p[ free_i ].p
    )
    {   G_(); Gd(line); Gh( free_p[ free_i ].p ); Gd( free_p[ free_i ].l ); V(); // lost
    }
        #endif
}
    #else
#define E_mem_Q_blk_I_assert_on_return(line)
    #endif
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_export
B
E_mem_Q_blk_T_eq( P p_1
, P p_2
, N l
){  for_n( i, l )
        if( *( (Pc)p_1 + i ) != *( (Pc)p_2 + i ))
            return no;
    return yes;
}
_internal
void
E_mem_Q_blk_I_copy_fwd( P dst
, P src
, N l
){
        #if defined( __i386__ ) || defined( __x86_64__ )
            #ifdef __SSE__
    N128 *dst_x = (P)E_simple_Z_p_I_align_up_to_v2( dst, sizeof(N128) );
    N128 *src_x = (P)E_simple_Z_p_I_align_up_to_v2( src, sizeof(N128) );
    N l_0 = (Pc)src_x - (Pc)src;
    if( l > l_0
    && l - l_0 >= sizeof(N128)
    && dst_x != src_x
    && (Pc)dst_x - (Pc)dst == (Pc)src_x - (Pc)src
    )
    {   N l_1 = ( l - l_0 ) / sizeof(N128);
        N l_2 = ( l - l_0 ) % sizeof(N128);
        __asm__ volatile (
        "\n"    "rep movsb"
        : "+D" (dst), "+S" (src), "+c" ( l_0 )
        :
        : "memory"
        );
        for_n( i, l_1 )
            __asm__ volatile (
            "\n"    "movaps %1,%%xmm0"
            "\n"    "movaps %%xmm0,%0"
            :
            : "p" ( dst_x++ ), "p" ( src_x++ )
            : "xmm0", "memory"
            );
        dst = dst_x;
        src = src_x;
        l = l_2;
    }
            #endif
    __asm__ volatile (
    "\n"    "rep movsb"
    : "+D" (dst), "+S" (src), "+c" (l)
    :
    : "memory"
    );
        #else
    Pn dst_n = (P)E_simple_Z_p_I_align_up_to_v2( dst, sizeof(N) );
    Pn src_n = (P)E_simple_Z_p_I_align_up_to_v2( src, sizeof(N) );
    N l_0 = (Pc)src_n - (Pc)src;
    if( l > l_0
    && l - l_0 >= sizeof(N)
    && dst_n != src_n
    && (Pc)dst_n - (Pc)dst == (Pc)src_n - (Pc)src
    )
    {   N l_1 = ( l - l_0 ) / sizeof(N);
        N l_2 = ( l - l_0 ) % sizeof(N);
        Pc dst_c = dst, src_c = src;
        for_n( i, l_0 )
        {   *dst_c = *src_c;
            dst_c++;
            src_c++;
        }
        for_n_( i, l_1 )
        {   *dst_n = *src_n;
            dst_n++;
            src_n++;
        }
        dst_c = (Pc)dst_n;
        src_c = (Pc)src_n;
        for_n_( i, l_2 )
        {   *dst_c = *src_c;
            dst_c++;
            src_c++;
        }
        return;
    }
    Pc dst_c = dst, src_c = src;
    for_n( i, l )
    {   *dst_c = *src_c;
        dst_c++;
        src_c++;
    }
        #endif
}
_internal
void
E_mem_Q_blk_I_copy_rev( P dst
, P src
, N l
){
        #if defined( __i386__ ) || defined( __x86_64__ )
    __asm__ volatile (
    "\n"    "std"
    );
            #ifdef __SSE__
    N128 *dst_x = (P)E_simple_Z_p_I_align_down_to_v2( dst + l, sizeof(N128) );
    N128 *src_x = (P)E_simple_Z_p_I_align_down_to_v2( src + l, sizeof(N128) );
    N l_0 = (Pc)src + l - (Pc)src_x;
    if( l > l_0
    && l - l_0 >= sizeof(N128)
    && dst_x != src_x
    && (Pc)dst + l - (Pc)dst_x == (Pc)src + l - (Pc)src_x
    )
    {   dst = (Pc)dst + l - 1;
        src = (Pc)src + l - 1;
        N l_1 = ( l - l_0 ) / sizeof(N128);
        N l_2 = ( l - l_0 ) % sizeof(N128);
        __asm__ volatile (
        "\n"    "rep movsb"
        : "+D" (dst), "+S" (src), "+c" ( l_0 )
        :
        : "memory"
        );
        for_n( i, l_1 )
            __asm__ volatile (
            "\n"    "movaps %1,%%xmm0"
            "\n"    "movaps %%xmm0,%0"
            :
            : "p" ( --dst_x ), "p" ( --src_x )
            : "xmm0", "memory"
            );
        dst = (P)( (Pc)dst_x - 1 );
        src = (P)( (Pc)src_x - 1 );
        l = l_2;
    }else
            #endif
    {   dst = (Pc)dst + l - 1;
        src = (Pc)src + l - 1;
    }
    __asm__ volatile (
    "\n"    "rep movsb"
    "\n"    "cld"
    : "+D" (dst), "+S" (src), "+c" (l)
    :
    : "memory"
    );
        #else
    Pn dst_n = (P)E_simple_Z_p_I_align_down_to_v2( (Pc)dst + l, sizeof(N) );
    Pn src_n = (P)E_simple_Z_p_I_align_down_to_v2( (Pc)src + l, sizeof(N) );
    N l_0 = (Pc)src + l - (Pc)src_n;
    if( l > l_0
    && l - l_0 >= sizeof(N)
    && dst_n != src_n
    && (Pc)dst + l - (Pc)dst_n == (Pc)src + l - (Pc)src_n
    )
    {   N l_1 = ( l - l_0 ) / sizeof(N);
        Pc dst_c = (Pc)dst + l, src_c = (Pc)src + l;
        for_n( i, l_0 )
        {   --dst_c;
            --src_c;
            *dst_c = *src_c;
        }
        for_n_( i, l_1 )
        {   --dst_n;
            --src_n;
            *dst_n = *src_n;
        }
        dst_c = (Pc)dst_n;
        src_c = (Pc)src_n;
        while( src_c != src )
        {   --dst_c;
            --src_c;
            *dst_c = *src_c;
        }
        return;
    }
    Pc dst_c = (Pc)dst + l, src_c = (Pc)src + l;
    while( src_c != src )
    {   --dst_c;
        --src_c;
        *dst_c = *src_c;
    }
        #endif
}
_export
void
E_mem_Q_blk_I_copy( P dst
, P src
, N l
){  if( !l
    || dst == src
    )
        return;
    if( (Pc)dst < (Pc)src
    || (Pc)dst >= (Pc)src + l
    )
        E_mem_Q_blk_I_copy_fwd( dst, src, l );
    else
        E_mem_Q_blk_I_copy_rev( dst, src, l );
}
_export
void
E_mem_Q_blk_P_fill_c( P p
, N l
, C c
){
        #if defined( __i386__ ) || defined( __x86_64__ )
            #ifdef __SSE__
    N128 *p_x = (P)E_simple_Z_p_I_align_up_to_v2( p, sizeof(N128) );
    N l_0 = (Pc)p_x - (Pc)p;
    if( l > l_0
    && l - l_0 >= sizeof(N128)
    )
    {   N l_1 = ( l - l_0 ) / sizeof(N128);
        N l_2 = ( l - l_0 ) % sizeof(N128);
        __asm__ volatile (
        "\n"    "rep stosb"
        : "+D" (p), "+c" ( l_0 )
        : "a" (c)
        : "memory"
        );
        N128 __attribute__ (( __aligned__(16) )) x;
        p = &x;
        N cx = sizeof(N128);
        __asm__ volatile (
        "\n"    "rep stosb"
        "\n"    "movaps %3,%%xmm0"
        : "+D" (p), "+c" (cx)
        : "a" (c), "m" (x)
        : "xmm0", "memory"
        );
        for_n( i, l_1 )
            __asm__ volatile (
            "\n"    "movaps %%xmm0,%0"
            :
            : "p" ( p_x++ )
            : "memory"
            );
        p = p_x;
        l = l_2;
    }
            #endif
    __asm__ volatile (
    "\n"    "rep stosb"
    : "+D" (p), "+c" (l)
    : "a" (c)
    : "memory"
    );
        #else
    Pn p_n = (P)E_simple_Z_p_I_align_up_to_v2( p, sizeof(N) );
    N l_0 = (Pc)p_n - (Pc)p;
    if( l > l_0
    && l - l_0 >= sizeof(N)
    )
    {   N l_1 = ( l - l_0 ) / sizeof(N);
        N l_2 = ( l - l_0 ) % sizeof(N);
        Pc p_c = p;
        for_n( i, l_0 )
            *p_c++ = c;
        N n = c;
        for_n_( i, sizeof(N) - 1 )
            n |= (N)c << ( i + 1 ) * 8;
        for_n_( i, l_1 )
            *p_n++ = n;
        p_c = (Pc)p_n;
        for_n_( i, l_2 )
            *p_c++ = c;
        return;
    }
    Pc p_c = p;
    for_n( i, l )
        *p_c++ = c;
        #endif
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_internal
void
E_mem_Q_blk_Q_sys_table_m_I_move_empty_entry( N mapped_i
){  struct E_mem_Q_blk_Z_mapped *mapped_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p;
    N mapped_end = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_mapped_id, (Pc)&mapped_p->p - (Pc)mapped_p ) + 1;
    if( mapped_end - ( mapped_i + 1 ))
        E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p + mapped_i * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].u
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p + ( mapped_i + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].u
        , ( mapped_end - ( mapped_i + 1 )) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].u
        );
    mapped_p[ mapped_end - 1 ].p = 0;
    mapped_p[ mapped_end - 1 ].l = 0;
}
_internal
void
E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( N free_i
){  struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
    N free_end = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p->p - (Pc)free_p ) + 1;
    if( free_end - ( free_i + 1 ))
        E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p + free_i * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].u
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p + ( free_i + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].u
        , ( free_end - ( free_i + 1 )) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].u
        );
    free_p[ free_end - 1 ].p = 0;
    free_p[ free_end - 1 ].l = 0;
}
_internal
void
E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( N allocated_i
){  struct E_mem_Q_blk_Z_allocated *allocated_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p;
    N allocated_end = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p->p - (Pc)allocated_p ) + 1;
    if( allocated_end - ( allocated_i + 1 ))
    {   E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p + allocated_i * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p + ( allocated_i + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
        , ( allocated_end - ( allocated_i + 1 )) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
        );
        if( allocated_i < E_base_S->E_mem_Q_blk_S_mapped_id )
            E_base_S->E_mem_Q_blk_S_mapped_id--;
        if( allocated_i < E_base_S->E_mem_Q_blk_S_free_id )
            E_base_S->E_mem_Q_blk_S_free_id--;
        if( allocated_i < E_base_S->E_mem_Q_blk_S_allocated_id )
            E_base_S->E_mem_Q_blk_S_allocated_id--;
    }
    allocated_p[ allocated_end - 1 ].p = 0;
}
_internal
N
E_mem_Q_blk_Q_sys_table_R_last( N table_i
, N rel_addr_p
){  for_n_rev( i, E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n )
    {   Pc *p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
        if( *p_ )
            break;
    }
    return i;
}
_internal
N
E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( N table_i
, N rel_addr_p
, N rel_addr_l
, N inserted_i
){  //G_(); Gd( table_i ); Gd( inserted_i );
    N n = E_mem_Q_blk_Q_sys_table_R_last( table_i, rel_addr_p );
    J_assert( inserted_i < n + 1 );
    if( !n ) // Tablica zawiera tylko jeden niepusty element czyli element wstawiony.
        return n;
    Pc tmp_p = *( Pc * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + inserted_i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
    J_assert( tmp_p );
    N min = 0;
    N max = n;
    N middle = max / 2;
    O{  if( middle == inserted_i )
            if( middle > min )
                middle--;
            else if( middle < max )
                middle++;
            else
                break;
        Pc *p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
        //G_(); Gd(min); Gd(middle); Gd(max); Gh( *p_ ); Gh( tmp_p );
        if( *p_ > tmp_p )
        {   if( middle == min )
                break;
            max = middle - 1;
            middle = max - ( middle - min ) / 2;
            if( middle == max
            && middle == min
            )
            {   p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
                if( *p_ < tmp_p )
                    middle++;
                break;
            }
        }else // if( *p_ < tmp_p )
        {   if( middle == max )
            {   middle++;
                break;
            }
            min = middle + 1;
            middle = min + ( max - middle ) / 2;
            if( middle == min
            && middle == max
            )
            {   p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
                if( *p_ < tmp_p )
                    middle++;
                break;
            }
        }
    }
    //G_(); Gd(middle);
    N tmp_l = *( N * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + inserted_i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l );
    if( middle != inserted_i )
        if( middle < inserted_i )
            E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + ( middle + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            , ( inserted_i - middle ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            );
        else // if( middle > inserted_i )
        {   middle--;
            E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + inserted_i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + ( inserted_i + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            , ( middle - inserted_i ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
            );
        }
    *( Pc * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = tmp_p;
    *( N * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + middle * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = tmp_l;
    return middle;
}
_internal
N
E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( N inserted_i
, N middle
){  //G_(); Gd( inserted_i ); Gd(middle);
    Pc tmp_p = E_base_S->E_mem_Q_blk_S_allocated[ inserted_i ].p;
    if( !~middle )
    {   struct E_mem_Q_blk_Z_allocated allocated_p;
        N n = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
        J_assert( inserted_i < n + 1 );
        if( !n ) // Tablica zawiera tylko jeden niepusty element czyli element wstawiony.
            return n;
        J_assert( tmp_p );
        N min = 0;
        N max = n;
        middle = max / 2;
        O{  if( middle == inserted_i )
                if( middle > min )
                    middle--;
                else
                    middle++;
            Pc p_ = E_base_S->E_mem_Q_blk_S_allocated[middle].p;
            //G_(); Gd(min); Gd(middle); Gd(max); Gh( p_ ); Gh( tmp_p );
            if( p_ > tmp_p )
            {   if( middle == min )
                    break;
                max = middle - 1;
                middle = max - ( middle - min ) / 2;
                if( middle == max
                && middle == min
                )
                {   p_ = E_base_S->E_mem_Q_blk_S_allocated[middle].p;
                    if( p_ < tmp_p )
                        middle++;
                    break;
                }
            }else // if( *p_ < tmp_p )
            {   if( middle == max )
                {   middle++;
                    break;
                }
                min = middle + 1;
                middle = min + ( max - middle ) / 2;
                if( middle == min
                && middle == max
                )
                {   p_ = E_base_S->E_mem_Q_blk_S_allocated[middle].p;
                    if( p_ < tmp_p )
                        middle++;
                    break;
                }
            }
        }
        //G_(); Gd(middle);
    }
    N tmp_n = E_base_S->E_mem_Q_blk_S_allocated[ inserted_i ].n;
    N tmp_u = E_base_S->E_mem_Q_blk_S_allocated[ inserted_i ].u;
    if( middle != inserted_i )
    {   if( middle < inserted_i )
            E_mem_Q_blk_I_copy( &E_base_S->E_mem_Q_blk_S_allocated[ middle + 1 ]
            , &E_base_S->E_mem_Q_blk_S_allocated[middle]
            , ( inserted_i - middle ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
            );
        else // if( middle > inserted_i )
        {   middle--;
            E_mem_Q_blk_I_copy( &E_base_S->E_mem_Q_blk_S_allocated[ inserted_i ]
            , &E_base_S->E_mem_Q_blk_S_allocated[ inserted_i + 1 ]
            , ( middle - inserted_i ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
            );
        }
        if( inserted_i == E_base_S->E_mem_Q_blk_S_mapped_id )
            E_base_S->E_mem_Q_blk_S_mapped_id = middle;
        else
        {   if( inserted_i < E_base_S->E_mem_Q_blk_S_mapped_id )
                E_base_S->E_mem_Q_blk_S_mapped_id--;
            if( middle <= E_base_S->E_mem_Q_blk_S_mapped_id )
                E_base_S->E_mem_Q_blk_S_mapped_id++;
        }
        if( inserted_i == E_base_S->E_mem_Q_blk_S_free_id )
            E_base_S->E_mem_Q_blk_S_free_id = middle;
        else
        {   if( inserted_i < E_base_S->E_mem_Q_blk_S_free_id )
                E_base_S->E_mem_Q_blk_S_free_id--;
            if( middle <= E_base_S->E_mem_Q_blk_S_free_id )
                E_base_S->E_mem_Q_blk_S_free_id++;
        }
        if( inserted_i == E_base_S->E_mem_Q_blk_S_allocated_id )
            E_base_S->E_mem_Q_blk_S_allocated_id = middle;
        else
        {   if( inserted_i < E_base_S->E_mem_Q_blk_S_allocated_id )
                E_base_S->E_mem_Q_blk_S_allocated_id--;
            if( middle <= E_base_S->E_mem_Q_blk_S_allocated_id )
                E_base_S->E_mem_Q_blk_S_allocated_id++;
        }
        E_base_S->E_mem_Q_blk_S_allocated[middle].p = tmp_p;
        E_base_S->E_mem_Q_blk_S_allocated[middle].n = tmp_n;
        E_base_S->E_mem_Q_blk_S_allocated[middle].u = tmp_u;
    }
    return middle;
}
_internal
B
E_mem_Q_blk_Q_sys_table_mf_I_unite( N table_i
, N rel_addr_p
, N rel_addr_l
, P p
, N l
){  //G_(); Gd( table_i ); Gh(p); Gh( (Pc)p + l );
    N i_found = ~0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( table_i, rel_addr_p );
    // Szukanie wolnego bloku przyległego od dołu.
    N min = 0;
    N max_0 = max;
    N i = max / 2;
    O{  Pc *p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
        N *l_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l );
        if( *p_ + *l_ == p )
        {   p = *p_;
            l = *l_ += l;
            i_found = i;
            min = i + 1;
            break;
        }
        if( *p_ + *l_ > (Pc)p )
        {   if( i == min )
                break;
            max = i - 1;
            i = max - ( i - min ) / 2;
        }else
        {   if( i == max )
            {   min = max + 1;
                break;
            }
            min = i + 1;
            i = min + ( max - i ) / 2;
        }
    }
    // Szukanie wolnego bloku przyległego od góry.
    max = max_0;
    if( min <= max )
    {   i = ( max - min ) / 2 + min;
        O{  Pc *p_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p );
            N *l_ = (P)( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l );
            if( (Pc)p + l == *p_ )
            {   if( ~i_found ) // Był znaleziony blok przyległy od dołu.
                {   *( Pc * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i_found * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) += *l_;
                    if( table_i == E_base_S->E_mem_Q_blk_S_mapped_id )
                        E_mem_Q_blk_Q_sys_table_m_I_move_empty_entry(i);
                    else
                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry(i);
                }else
                {   *p_ = p;
                    *l_ += l;
                    i_found = i;
                }
                break;
            }
            if( *p_ > (Pc)p + l )
            {   if( i == min )
                    break;
                max = i - 1;
                i = max - ( i - min ) / 2;
            }else
            {   if( i == max )
                    break;
                min = i + 1;
                i = min + ( max - i ) / 2;
            }
        }
    }
    return !!~i_found;
}
_internal
N
E_mem_Q_blk_Q_sys_table_mf_P_put( N table_i
, N rel_addr_p
, N rel_addr_l
, P p
, N l
){  //G_(); Gd( table_i ); Gh(p); Gh( (Pc)p + l );
    if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( table_i, rel_addr_p, rel_addr_l, p, l ))
    {   if( table_i == E_base_S->E_mem_Q_blk_S_free_id
        && l >= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
        )
        {   if( (Pc)p + l == E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p ) // Nowy blok jest przyległy od dołu do tablicy bloków.
            {   E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p -= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p;
                if( l - E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u )
                {   free_p[0].l = l - E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                    free_p[0].p = p;
                    E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, 0 );
                }else
                    E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry(0);
                return 0;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u == p ) // Nowy blok jest przyległy od góry do tablicy bloków.
            {   N i = E_mem_Q_blk_Q_sys_table_R_last( table_i, rel_addr_p ) + 1;
                struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ].p = 0;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ].l = 0;
                free_p[i].l = l - E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                free_p[i].p = free_p[i].l
                ? (Pc)p + E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
                : 0;
                E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                if( free_p[i].l )
                    E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, i );
                return 0;
            }
        }
        N i = E_mem_Q_blk_Q_sys_table_M_new_id( table_i, rel_addr_p, rel_addr_l, p, l );
        if( !~i )
            //TODO Dopisać ewentualne przeniesienie tablicy wolnych bloków do tego nowego bloku.
            return ~0;
    }
    return 0;
}
_internal
N
E_mem_Q_blk_Q_sys_table_M_new_id( N table_i
, N rel_addr_p
, N rel_addr_l
, P p // Adres do nowego wpisu.
, N l // I rozmiar.
){  //G_(); Gd( table_i ); Gh(p); Gh( p + l );
    Pc p_0 = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p;
    N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
    N i = E_mem_Q_blk_Q_sys_table_R_last( table_i, rel_addr_p ) + 1;
    if( table_i == E_base_S->E_mem_Q_blk_S_mapped_id
    || table_i == E_base_S->E_mem_Q_blk_S_free_id
    )
    {   if( i != E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n )
        {   if(p)
            {   *( P * )( p_0 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
                *( N * )( p_0 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
                i = E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, i );
            }
            return i;
        }
        struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
        N l_ = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
        struct E_mem_Q_blk_Z_free free_p_;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
        // Szukanie wolnego bloku przyległego od dołu.
        N min = 0;
        N max_0 = max;
        N free_i = max / 2;
        O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
            {   if( free_p[ free_i ].l >= l_ )
                {   free_p[ free_i ].l -= l_;
                    if( !free_p[ free_i ].l )
                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                    E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p -= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                    E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p
                    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
                    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
                    );
                    N i = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n;
                    *( P * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
                    *( N * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
                    E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                    if(p)
                        i = E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, i );
                    return i;
                }
                min = i + 1;
                break;
            }
            if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
            {   if( free_i == min )
                    break;
                max = free_i - 1;
                free_i = max - ( free_i - min ) / 2;
            }else
            {   if( free_i == max )
                {   min = max + 1;
                    break;
                }
                min = free_i + 1;
                free_i = min + ( max - free_i ) / 2;
            }
        }
        // Szukanie wolnego bloku przyległego od góry.
        max = max_0;
        if( min <= max )
        {   free_i = ( max - min ) / 2 + min;
            O{  if( p_0 + l_0 == free_p[ free_i ].p )
                {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u )
                    {   if( free_p[ free_i ].l -= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u )
                            free_p[ free_i ].p += E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                        else
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        *( P * )( p_0 + l_0 + rel_addr_p ) = p;
                        *( N * )( p_0 + l_0 + rel_addr_l ) = l;
                        E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                        return p ? E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n - 1 ) : E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n - 1;
                    }
                    break;
                }
                if( free_p[ free_i ].p > p_0 + l_0 )
                {   if( free_i == min )
                        break;
                    max = free_i - 1;
                    free_i = max - ( free_i - min ) / 2;
                }else
                {   if( free_i == max )
                        break;
                    min = free_i + 1;
                    free_i = min + ( max - free_i ) / 2;
                }
            }
        }
    }else
    {   if( i != E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n )
        {   if(p)
            {   *( P * )( p_0 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
                *( N * )( p_0 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
                i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( i, ~0 );
            }
            return i;
        }
        struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
        N l_ = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
        struct E_mem_Q_blk_Z_free free_p_;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
        // Szukanie wolnego bloku przyległego od dołu.
        N min = 0;
        N max_0 = max;
        N free_i = max / 2;
        O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
            {   if( free_p[ free_i ].l >= l_ )
                {   free_p[ free_i ].l -= l_;
                    if( !free_p[ free_i ].l )
                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                    E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p -= l_;
                    E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p
                    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + l_
                    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
                    );
                    E_base_S->E_mem_Q_blk_S_allocated = (P)E_base_S->E_mem_Q_blk_S_allocated[ table_i - 1 ].p;
                    N i = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n;
                    *( P * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
                    *( N * )( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
                    E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                    if(p)
                        i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( i, ~0 );
                    return i;
                }
                min = i + 1;
                break;
            }
            if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
            {   if( free_i == min )
                    break;
                max = free_i - 1;
                free_i = max - ( free_i - min ) / 2;
            }else
            {   if( free_i == max )
                {   min = max + 1;
                    break;
                }
                min = free_i + 1;
                free_i = min + ( max - free_i ) / 2;
            }
        }
        // Szukanie wolnego bloku przyległego od góry.
        max = max_0;
        if( min <= max )
        {   free_i = ( max - min ) / 2 + min;
            O{  if( p_0 + l_0 == free_p[ free_i ].p )
                {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u )
                    {   free_p[ free_i ].l -= E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                        if( free_p[ free_i ].l )
                            free_p[ free_i ].p += E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u;
                        else
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        *( P * )( p_0 + l_0 + rel_addr_p ) = p;
                        *( N * )( p_0 + l_0 + rel_addr_l ) = l;
                        E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                        return p ? E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n - 1, ~0 ) : E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n - 1;
                    }
                    break;
                }
                if( free_p[ free_i ].p > p_0 + l_0 )
                {   if( free_i == min )
                        break;
                    max = free_i - 1;
                    free_i = max - ( free_i - min ) / 2;
                }else
                {   if( free_i == max )
                        break;
                    min = free_i + 1;
                    free_i = min + ( max - free_i ) / 2;
                }
            }
        }
    }
    Pc p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &table_i
    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u
    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n + 1
    , E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ? p_0 : 0
    , l_0
    , 0
    , ~0
    );
    if( !p_1 )
        return ~0;
    i = E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n - 1;
    if( table_i == E_base_S->E_mem_Q_blk_S_mapped_id
    || table_i == E_base_S->E_mem_Q_blk_S_free_id
    )
        if(p)
        {   E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n--;
            N i = E_mem_Q_blk_Q_sys_table_R_last( table_i, rel_addr_p ) + 1;
            if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( table_i, rel_addr_p, rel_addr_l, p, l ))
            {   if( i != E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n )
                {   *( P * )( p_1 + ( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = 0;
                    *( N * )( p_1 + ( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = 0;
                }
                *( P * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
                *( N * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
                E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
                i = E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( table_i, rel_addr_p, rel_addr_l, i );
            }else
            {   *( P * )( p_1 + ( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = 0;
                *( N * )( p_1 + ( E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n ) * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = 0;
                E_base_S->E_mem_Q_blk_S_allocated[ table_i ].n++;
            }
        }else
        {   *( P * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = 0;
            *( N * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = 0;
        }
    else
    {   *( P * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_p ) = p;
        *( N * )( p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ table_i ].u + rel_addr_l ) = l;
        if(p)
            i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( i, ~0 );
    }
    return i;
}
_internal
void
E_mem_Q_blk_Q_table_I_put_begin( N *allocated_or_table_i
){  J_assert( E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n != J_a_R_n( E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id ));
    E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id[ E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n++ ] = allocated_or_table_i;
}
_internal
void
E_mem_Q_blk_Q_table_I_put_before( N table_i
){  E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_table_id[ E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n - 1 ] = table_i;
}
_internal
void
E_mem_Q_blk_Q_table_I_put_after( N table_i
){  for_n( i, E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n )
    {   N *allocated_or_table_i = E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id[i];
        if( E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_table_id[ E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n - 1 ] < *allocated_or_table_i
        && table_i >= *allocated_or_table_i
        )
            (*allocated_or_table_i)--;
        else if( E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_table_id[ E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n - 1 ] > *allocated_or_table_i
        && table_i <= *allocated_or_table_i
        )
            (*allocated_or_table_i)++;
    }
}
_internal
void
E_mem_Q_blk_Q_table_I_put_end( void
){  J_assert( E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n );
    E_base_S->E_mem_Q_blk_Q_table_M_from_free_or_map_S_allocated_id_n--;
}
_internal
N
E_mem_Q_blk_I_default_align( N u
){  N align;
    // Spekulacje.
    if( u > E_mem_Q_blk_S_align_to_all
    && u % E_mem_Q_blk_S_align_to_all == 0
    )
        align = E_mem_Q_blk_S_align_to_all;
    else if( u == E_mem_Q_blk_S_align_to_all )
        align = u;
    else if( u
    && u < E_mem_Q_blk_S_align_to_all
    && E_simple_Z_n_T_power_2(u)
    )
        align = u;
    else
        align = 1;
    return align;
}
// Dla tablic systemowych “mapped” i “free” ‘alokuje’ tyle “n”, ile żądane, lub więcej.
_internal
P
E_mem_Q_blk_Q_table_M_from_free_or_map( N *allocated_or_table_i
, N u
, N n
, P p // Adres uprzedniej zawartości lub 0, gdy brak.
, N l // I rozmiar. Jeśli “p == 0”, to parametr ignorowany.
, N l_rel
, N align
){  N l_1 = n * u;
    //G_(); Gd( *allocated_or_table_i ); Gh( l_1 ); Gd( l_rel ); Gh(p); Gh( (Pc)p + l );
    //G_(); Gd( E_base_S->E_mem_Q_blk_S_mapped_id ); Gd( E_base_S->E_mem_Q_blk_S_free_id ); Gd( E_base_S->E_mem_Q_blk_S_allocated_id );
    Pc p_1;
    S i = 0;
    if(n)
    {   if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id
        && p // Uprzedni obszar tablicy staje się wolnym blokiem.
        )
        {   n++;
            l_1 += u;
        }
        N l_align;
        if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_allocated_id
        || *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id
        || *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id
        )
            l_align = sizeof(N);
        else if( ~align )
        {   J_assert( E_simple_Z_n_T_power_2(align) );
            l_align = align;
        }else
            l_align = E_mem_Q_blk_I_default_align(u);
        if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id ) // Dla ewentualnego ‘mapowania’ tablicy wolnych bloków.
        {   n += 2;
            l_1 += 2 * u;
        }else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // Obszar przed wyrównanym adresem staje się wolnym blokiem (1 u) oraz dla ewentualnego ‘mapowania’ tablicy zmapowanych bloków (2 u).
        {   n += 3;
            l_1 += 3 * u;
        }
        N l_ = ~0;
        N i_found;
        struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
        for_n( free_i, E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n ) // Szukanie wolnego bloku na całą tablicę.
        {   p_1 = E_simple_Z_p_I_align_up_to_v2( free_p[ free_i ].p, l_align );
            if( free_p[ free_i ].l >= ( p_1 - free_p[ free_i ].p ) + l_1
            && free_p[ free_i ].l < l_
            )
            {   l_ = free_p[ free_i ].l;
                i_found = free_i;
                if( l_ == ( p_1 - free_p[ free_i ].p ) + l_1 )
                    break;
            }
        }
        //G_(); Gh( l_ ); Gd( i_found );
        if( !~l_ )
        {   // Jeśli żądanie ‘alokacji’ tablicy systemowej “mapped” lub “free” przyszło z rekurencji, to wtedy żądanie ‘alokacji’ takiej tablicy oznacza brak wolnych wpisów na poprzednią czekającą ‘alokację’ ogólną lub tablicy “allocated”, a za chwilę będą być może potrzebne jeszcze kolejne wpisy na bieżącą ‘alokację’. Dlatego należy ‘alokować’ odrazu minimalną ilość rezerwowych wpisów (dla jednej tablicy, by nie wymuszać statycznie jednoczesnej ‘realokacji’ obu tablic), ponieważ w pesymistycznym przypadku ewentualne ‘doalokowanie’ jednej nadmiarowej strony pamięci na nie wykorzystane rezerwowe wpisy mniej kosztuje niż drugie kopiowanie tej samej tablicy dla ‘alokacji’ kolejnych wpisów w tej kolejnej rekurencji.
            if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // Obszar przed wyrównanym adresem nie staje się wolnym blokiem (-1 u) oraz dla ewentualnego ‘mapowania’ tablicy zmapowanych bloków (2 u).
            {   n++;
                l_1 += u;
            }
            Pc src_page, src_page_end;
            if(p) // Będzie kopiowanie, a teraz przygotowanie do ‘remapowania’ ‚środka’ zamiast kopiowania.
            {   src_page = E_simple_Z_p_I_align_up_to_v2( (Pc)p, E_base_S->E_mem_S_page_size );
                src_page_end = E_simple_Z_p_I_align_down_to_v2( (Pc)p + l, E_base_S->E_mem_S_page_size );
                // Zapewnienie liczby wpisów w tablicy systemowej właśnie ‘realokowanej’— potrzebnej dla pesymistycznego przypadku niescalenia z już obecnymi nowych bloków dodawanych w tym wywołaniu procedury do takiej tablicy— by nie mogło wystąpić rekurencyjne, zapętlające wywołanie tej procedury dla tej samej tablicy bez możliwości uzyskania nowych wpisów.
                if( src_page < src_page_end ) // Będzie ‘remapowanie’ wewnętrznych “stron” pamięci (bloków o adresach wyrównanych do rozmiaru “strony”).
                {   if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // Zostaną one wzięte z obszaru dostępnych wolnych bloków (‘przemapowane’), a krańcowe pozostałości (od obszaru wyrównanego do “stron” pamięci) staną się wolnymi blokami.
                    {   n--; // Nie będzie potrzeba osobno wpisywać uprzedniego rozmiaru tablicy.
                        l_1 -= u;
                        if( src_page != p ) // Będzie wolny początkowy fragment w pierwszej “stronie” pamięci: w źródłowym bloku i nowym.
                        {   n += 2;
                            l_1 += 2 * u;
                        }
                        if( src_page_end != (Pc)p + l ) // Będzie wolny końcowy fragment w ostatniej “stronie” pamięci: w źródłowym bloku i nowym.
                        {   n += 2;
                            l_1 += 2 * u;
                        }
                    }else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id ) // Zostaną one wzięte z obszaru ‘zmapowanych’, a krańcowe “strony” staną się osobnymi ‘zmapowanymi’ blokami.
                    {   n += 2;
                        l_1 += 2 * u;
                    }
                }else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id // Nowy blok, ‘zmapowany’ na tablicę ‘zmapowanych’ — musi być wpisany do tablicy.
                || *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id // Fragment pozostały do wyrównania do rozmiaru “stron” pamięci staje się wolnym blokiem.
                )
                {   n++;
                    l_1 += u;
                }
            }else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // Fragment pozostały do wyrównania do rozmiaru “stron” pamięci staje się wolnym blokiem (1 u).
            {   n++;
                l_1 += u;
            }
            N dst_rel = 0;
            if( p
            && src_page < src_page_end
            )
            {   l_ = E_simple_Z_n_I_align_up_to_v2( l_1 - ( src_page - (Pc)p ), E_base_S->E_mem_S_page_size );
                l_ += dst_rel = E_simple_Z_n_I_align_up_to_v2( l_rel + ( src_page - (Pc)p ), E_base_S->E_mem_S_page_size );
            }else
                l_ = E_simple_Z_n_I_align_up_to_v2( l_1, E_base_S->E_mem_S_page_size );
                #if defined( __gnu_linux__ )
            if( E_base_S->E_flow_Z_task_stacks_S_n_pages < l_ / E_base_S->E_mem_S_page_size )
            {   N n_pages;
                V1_( n_pages = sysconf( _SC_AVPHYS_PAGES ));
                E_base_S->E_flow_Z_task_stacks_S_n_pages = n_pages;
                if( n_pages < l_ / E_base_S->E_mem_S_page_size )
                    return 0;
            }
            V1p( p_1 = mmap( 0
            , l_
            , PROT_READ | PROT_WRITE
            , MAP_PRIVATE
            | MAP_ANONYMOUS | MAP_UNINITIALIZED
            , -1
            , 0
            ))
                #elif defined( __FreeBSD__ ) || defined( __NetBSD__ ) || defined( __OpenBSD__ )
            V1p( p_1 = mmap( 0
            , l_
            , PROT_READ | PROT_WRITE
            , MAP_PRIVATE
            | MAP_ANON
            , -1
            , 0
            ))
                #else
#error not implemented
                #endif
                return 0;
                #ifdef E_mem_Q_blk_C_debug
            E_mem_Q_blk_P_fill_c( p_1, l_, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            if( U_R( E_base_S->E_flow_S_mode, Z_task_table_S_can_read ))
            {   E_base_S->E_flow_Z_task_stacks_S_n_pages -= l_ / E_base_S->E_mem_S_page_size;
                N failed_tasks = E_flow_Q_task_I_granulation();
                if( failed_tasks )
                {   GV_(NDFN); Gd( -failed_tasks );
                }
            }
            Pc dst_page;
            Pc p_ = p_1;
            if(p)
            {   //TODO Poniżej być może zastąpić (bez deintegracji) procedurą “move”, która powstanie.
                if( src_page < src_page_end )
                {   dst_page = p_1 + dst_rel;
                    p_ = dst_page - ( src_page - (Pc)p );
                    E_mem_Q_blk_I_copy( p_, p, src_page - (Pc)p );
                    p_ -= l_rel;
                    Pc src_page_ = src_page, dst_page_end = dst_page;
                    while( src_page_ != src_page_end )
                    {
                            #if defined( __gnu_linux__ )
                        V1p_( mremap( src_page_
                        , E_base_S->E_mem_S_page_size
                        , E_base_S->E_mem_S_page_size
                        , MREMAP_MAYMOVE | MREMAP_FIXED
                        , dst_page_end
                        ));
                            #elif defined( __FreeBSD__ ) || defined( __NetBSD__ ) || defined( __OpenBSD__ )
                        // Kopiowanie po jednej “stronie”, by tak właśnie zachodziło rzeczywiste ‘mapowanie’ w sprzętowym trybie “map on write”, gdy pojedyncze “strony” są też ‘odmapowywane’.
                        E_mem_Q_blk_I_copy( dst_page_end, src_page_, E_base_S->E_mem_S_page_size );
                        V0_( munmap( src_page_, E_base_S->E_mem_S_page_size ));
                            #else
#error not implemented
                            #endif
                        src_page_ += E_base_S->E_mem_S_page_size;
                        dst_page_end += E_base_S->E_mem_S_page_size;
                    }
                        #if 0 && defined( __gnu_linux__ )
#error nie działa ‘remapowanie’ całego bloku naraz, a tylko po “stronie”, jak powyżej.
                    V1p_( mremap( src_page
                    , src_page_end - src_page
                    , src_page_end - src_page
                    , MREMAP_MAYMOVE | MREMAP_FIXED
                    , dst_page
                    ));
                    Pc dst_page_end = dst_page + ( src_page_end - src_page );
                        #endif
                    E_mem_Q_blk_I_copy( dst_page_end, src_page_end, (Pc)p + l - src_page_end );
                }else
                    E_mem_Q_blk_I_copy( p_1 + l_rel, p, l );
                if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_allocated_id )
                    E_base_S->E_mem_Q_blk_S_allocated = (P)p_;
            }else
                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].u = u;
            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].p = p_;
            *allocated_or_table_i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( *allocated_or_table_i, ~0 );
            E_mem_Q_blk_Q_table_I_put_begin( allocated_or_table_i );
            struct E_mem_Q_blk_Z_mapped mapped_p_;
            struct E_mem_Q_blk_Z_free free_p_;
            if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id )
            {   if( src_page < src_page_end )
                {   N min = 0;
                    N max = E_mem_Q_blk_Q_sys_table_R_last( *allocated_or_table_i, (Pc)&mapped_p_.p - (Pc)&mapped_p_ );
                    N middle = max / 2;
                    struct E_mem_Q_blk_Z_mapped *mapped_p = (P)p_;
                    O{  Pc p_end = mapped_p[middle].p + mapped_p[middle].l;
                        if( mapped_p[middle].p <= (Pc)p
                        && (Pc)p < p_end
                        )
                        {   N before_l = src_page - mapped_p[middle].p;
                            if( before_l )
                                mapped_p[middle].l = before_l;
                            else
                            {   E_mem_Q_blk_Q_sys_table_m_I_move_empty_entry(middle);
                                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n--;
                                i--;
                            }
                            if( (Pc)p + l != p_end )
                            {   mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = src_page_end;
                                mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = p_end - src_page_end;
                                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                                E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&mapped_p_.p - (Pc)&mapped_p_, (Pc)&mapped_p_.l - (Pc)&mapped_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                                i++;
                            }
                            break;
                        }
                        if( mapped_p[middle].p > (Pc)p )
                        {   max = middle - 1;
                            middle = max - ( middle - min ) / 2;
                        }else
                        {   min = middle + 1;
                            middle = min + ( max - middle ) / 2;
                        }
                    }
                }
                struct E_mem_Q_blk_Z_mapped *mapped_p = (P)p_;
                if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&mapped_p_.p - (Pc)&mapped_p_, (Pc)&mapped_p_.l - (Pc)&mapped_p_, p_1, l_ ))
                {   mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p_1;
                    mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = l_;
                    E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                    E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&mapped_p_.p - (Pc)&mapped_p_, (Pc)&mapped_p_.l - (Pc)&mapped_p_ , E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                    i++;
                }
                S start_i = i;
                if( src_page < src_page_end )
                    for( ; i != 4; i++ )
                    {   mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
                        mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
                    }
                else
                    for( ; i != 3; i++ )
                    {   mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
                        mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
                    }
                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n = n - 1;
            }else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) //TODO Wyeliminować “unite” tam, gdzie nigdy nie zajdzie.
            {   free_p = (P)p_;
                if( src_page < src_page_end )
                {   if( src_page != p )
                    {   if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, src_page - (Pc)p ))
                        {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p;
                            free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = src_page - (Pc)p;
                            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                            E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                            i++;
                        }
                        if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_1, p_ - p_1 ))
                        {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p_1;
                            free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = p_ - p_1;
                            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                            E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                            i++;
                        }
                    }
                    if( src_page_end != (Pc)p + l )
                    {   if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, src_page_end, (Pc)p + l - src_page_end ))
                        {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = src_page_end;
                            free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = (Pc)p + l - src_page_end;
                            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                            E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                            i++;
                        }
                        if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_ + l_1, p_1 + l_ - ( p_ + l_1 )))
                        {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p_ + l_1;
                            free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = p_1 + l_ - ( p_ + l_1 );
                            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                            E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                            i++;
                        }
                    }
                    N start_i = i;
                    for( ; i != 9; i++ )
                    {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
                        free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
                    }
                }else
                {   if( l_ != l_1
                    && !E_mem_Q_blk_Q_sys_table_mf_I_unite( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_1 + l_1, l_ - l_1 )
                    )
                    {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p_1 + l_1;
                        free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = l_ - l_1;
                        E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                        E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                        i++;
                    }
                    if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l ))
                    {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p;
                        free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = l;
                        E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                        E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                        i++;
                    }
                    N start_i = i;
                    for( ; i != 6; i++ )
                    {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
                        free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
                    }
                }
                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n = n - 1;
            }
            if( *allocated_or_table_i != E_base_S->E_mem_Q_blk_S_mapped_id )
            {   if( p
                && src_page < src_page_end
                )
                {   N min = 0;
                    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_mapped_id, (Pc)&mapped_p_.p - (Pc)&mapped_p_ );
                    N middle = max / 2;
                    struct E_mem_Q_blk_Z_mapped *mapped_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p;
                    O{  Pc p_end = mapped_p[middle].p + mapped_p[middle].l;
                        if( mapped_p[middle].p <= (Pc)p
                        && (Pc)p < p_end
                        )
                        {   N before_l = src_page - mapped_p[middle].p;
                            if( before_l )
                                mapped_p[middle].l = before_l;
                            else
                                E_mem_Q_blk_Q_sys_table_m_I_move_empty_entry(middle);
                            if( (Pc)p + l != p_end )
                            {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_mapped_id );
                                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_mapped_id, (Pc)&mapped_p_.p - (Pc)&mapped_p_, (Pc)&mapped_p_.l - (Pc)&mapped_p_, src_page_end, p_end - src_page_end ))
                                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_mapped_id );
                                    E_mem_Q_blk_Q_table_I_put_end();
                                    return 0;
                                }
                                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_mapped_id );
                            }
                            break;
                        }
                        if( mapped_p[middle].p > (Pc)p )
                        {   max = middle - 1;
                            middle = max - ( middle - min ) / 2;
                        }else
                        {   min = middle + 1;
                            middle = min + ( max - middle ) / 2;
                        }
                    }
                }
                E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_mapped_id );
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_mapped_id, (Pc)&mapped_p_.p - (Pc)&mapped_p_, (Pc)&mapped_p_.l - (Pc)&mapped_p_, p_1, l_ ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_mapped_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_mapped_id );
            }
            if( *allocated_or_table_i != E_base_S->E_mem_Q_blk_S_free_id )
            {   if( p
                && src_page < src_page_end
                )
                {   if( src_page != p )
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, src_page - (Pc)p ))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    }
                    if( p_ != p_1 )
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_1, p_ - p_1 ))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    }
                    if( src_page_end != (Pc)p + l )
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, src_page_end, (Pc)p + l - src_page_end ))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    }
                    if( p_1 + l_ != p_ + l_rel + l_1 )
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_ + l_rel + l_1, p_1 + l_ - ( p_ + l_rel + l_1 )))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    }
                }else
                {   if( l_ != l_1 )
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_1 + l_1, l_ - l_1 ))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    }
                    if(p)
                    {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l ))
                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                            E_mem_Q_blk_Q_table_I_put_end();
                            return 0;
                        }
                        E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                }
                }
            }
            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n = n;
            E_mem_Q_blk_Q_table_I_put_end();
            return p_;
        }
        Pc old_free_p = free_p[ i_found ].p;
        p_1 = E_simple_Z_p_I_align_up_to_v2( old_free_p, l_align );
        free_p[ i_found ].l -= ( p_1 - old_free_p ) + l_1;
        if( free_p[ i_found ].l )
            free_p[ i_found ].p += ( p_1 - old_free_p ) + l_1;
        else
            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( i_found );
        if(p)
        {   E_mem_Q_blk_I_copy( p_1 + l_rel, p, l );
            if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_allocated_id )
                E_base_S->E_mem_Q_blk_S_allocated = (P)p_1;
        }
        E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].p = p_1;
        *allocated_or_table_i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( *allocated_or_table_i, ~0 );
        if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_mapped_id )
        {   struct E_mem_Q_blk_Z_mapped *mapped_p = (P)p_1;
            mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = 0;
            mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = 0;
            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
            mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = 0;
            mapped_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = 0;
            E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
        }
        E_mem_Q_blk_Q_table_I_put_begin( allocated_or_table_i );
        if( p_1 - old_free_p )
            if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id )
            {   free_p = (P)p_1;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = old_free_p;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = p_1 - old_free_p;
                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                struct E_mem_Q_blk_Z_free free_p_;
                E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                i++;
            }else
            {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, old_free_p, p_1 - old_free_p ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
            }
    }else
    {   N allocated_i_sorted_pos;
        if( !( p_1 = E_mem_Q_blk_M_0( &allocated_i_sorted_pos )))
            return 0;
        E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].p = p_1;
        *allocated_or_table_i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( *allocated_or_table_i, allocated_i_sorted_pos );
        E_mem_Q_blk_Q_table_I_put_begin( allocated_or_table_i );
    }
    if( !p ) //NDFN Rozpoznanie niebezpośrednie, mimo że jednoznaczne w obecnej implementacji.
        E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].u = u;
    if(p)
        if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // if(n)
        {   struct E_mem_Q_blk_Z_free *free_p = (P)p_1;
            struct E_mem_Q_blk_Z_free free_p_;
            if( !E_mem_Q_blk_Q_sys_table_mf_I_unite( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l ))
            {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].p = p;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n ].l = l;
                E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n++;
                E_mem_Q_blk_Q_sys_table_mf_I_sort_inserted( *allocated_or_table_i, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n - 1 );
                i++;
            }
            N start_i = i;
            for( ; i != 4; i++ )
            {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
                free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
            }
        }else
        {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
            struct E_mem_Q_blk_Z_free free_p_;
            if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l ))
            {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                E_mem_Q_blk_Q_table_I_put_end();
                return 0;
            }
            E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
        }
    else if( *allocated_or_table_i == E_base_S->E_mem_Q_blk_S_free_id ) // if(n)
    {   struct E_mem_Q_blk_Z_free *free_p = (P)p_1;
        N start_i = i;
        for( ; i != 4; i++ )
        {   free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].p = 0;
            free_p[ E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n + i - start_i ].l = 0;
        }
    }
    E_base_S->E_mem_Q_blk_S_allocated[ *allocated_or_table_i ].n = n;
    E_mem_Q_blk_Q_table_I_put_end();
    return p_1;
}
_internal
__attribute__ (( __malloc__( E_mem_Q_blk_W )))
P
E_mem_Q_blk_M_0( N *allocated_i_sorted_pos
){  Pc p_end;
    V1p_( p_end = sbrk(0) );
    Pc p = (P)1;
    N allocated_i = 0;
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N allocated_max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    do
    {   if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p != p )
            break;
        if( ++p == p_end )
            return 0;
    }while( allocated_i++ != allocated_max );
    *allocated_i_sorted_pos = allocated_i;
    return p;
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_export
N
E_mem_Q_sys_table_I_reduce( void
){  _single_thread_begin;
    struct E_mem_Q_blk_Z_allocated allocated_p_;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p_.p - (Pc)&allocated_p_ );
    if( max != E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].n - 1 )
    {   N n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].n;
        E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].n = max + 1;
        struct E_mem_Q_blk_Z_free free_p_;
        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id
        , (Pc)&free_p_.p - (Pc)&free_p_
        , (Pc)&free_p_.l - (Pc)&free_p_
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].p + ( max + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u
        , ( n - 1 - max ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_allocated_id ].u ))
        {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
            _single_thread_end;
            return ~0;
        }
    }
    struct E_mem_Q_blk_Z_mapped mapped_p_;
    max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_mapped_id, (Pc)&mapped_p_.p - (Pc)&mapped_p_ );
    if( max != E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].n - 1 )
    {   N n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].n;
        E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].n = max + 1;
        struct E_mem_Q_blk_Z_free free_p_;
        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id
        , (Pc)&free_p_.p - (Pc)&free_p_
        , (Pc)&free_p_.l - (Pc)&free_p_
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].p + ( max + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].u
        , ( n - 1 - max ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_mapped_id ].u ))
        {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
            _single_thread_end;
            return ~0;
        }
    }
    struct E_mem_Q_blk_Z_free free_p_;
    max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
    if( !~max )
        max++;
    if( max != E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n - 1 )
    {   N n = E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n;
        E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].n = max + 1;
        struct E_mem_Q_blk_Z_free free_p_;
        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id
        , (Pc)&free_p_.p - (Pc)&free_p_
        , (Pc)&free_p_.l - (Pc)&free_p_
        , E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p + ( max + 1 ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].u
        , ( n - 1 - max ) * E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].u ))
        {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
            _single_thread_end;
            return ~0;
        }
    }
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    return 0;
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_export
P
E_mem_Q_blk_M( N l
){  return E_mem_Q_blk_M_tab( 1, l );
}
_export
P
E_mem_Q_blk_M_tab(
  N u
, N n
){  return E_mem_Q_blk_M_align_tab( u, n, ~0 );
}
_export
P
E_mem_Q_blk_M_align( N l
, N align
){  return E_mem_Q_blk_M_align_tab( 1, l, align );
}
_export
__attribute__ (( __malloc__( E_mem_Q_blk_W )))
P
E_mem_Q_blk_M_align_tab(
  N u
, N n
, N align
){  J_assert(u);
    J_assert( !E_simple_T_multiply_overflow( n, u ));
    J_assert(align);
    _single_thread_begin;
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N allocated_i = E_mem_Q_blk_Q_sys_table_M_new_id( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p, (Pc)&allocated_p.n - (Pc)&allocated_p, 0, 0 );
    if( !~allocated_i )
    {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
        _single_thread_end;
        return 0;
    }
    if( !E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i, u, n, 0, 0, 0, align ))
    {   E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
        E_mem_Q_blk_I_assert_on_return( __LINE__ );
        _single_thread_end;
        return 0;
    }
        #ifdef E_mem_Q_blk_C_debug
    if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
        E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
        #endif
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    P p_ = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
    _single_thread_end;
    return p_;
}
_export
P
E_mem_Q_blk_M_replace( P p
, N l
){  return E_mem_Q_blk_M_replace_tab( p, 1, l );
}
_export
__attribute__ (( __malloc__( E_mem_Q_blk_W )))
P
E_mem_Q_blk_M_replace_tab( P p
, N u
, N n
){  J_assert(u);
    J_assert( !E_simple_T_multiply_overflow( n, u ));
    _single_thread_begin;
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   if( !E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n
            && !n
            )
            {   E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u = u;
                P p_ = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                _single_thread_end;
                return p_;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   E_mem_Q_blk_Q_table_I_put_begin( &allocated_i );
                E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                E_mem_Q_blk_Q_table_I_put_end();
            }
            if( !E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i, u, n, 0, 0, 0, ~0 ))
            {   E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
                E_mem_Q_blk_I_assert_on_return( __LINE__ );
                _single_thread_end;
                *( P * )p = 0;
                return 0;
            }
                #ifdef E_mem_Q_blk_C_debug
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
                E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            E_mem_Q_blk_I_assert_on_return( __LINE__ );
            P p_ = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
            _single_thread_end;
            *( P * )p = p_;
            return p_;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    _single_thread_end;
    GV_(NXP); Gh(p); V();
}
_export
__attribute__ (( __malloc__( E_mem_Q_blk_W )))
P
E_mem_Q_blk_M_split( P p
, N i
){  J_assert(i);
    _single_thread_begin;
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N allocated_i = E_mem_Q_blk_Q_sys_table_M_new_id( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p, (Pc)&allocated_p.n - (Pc)&allocated_p, 0, 0 );
    if( !~allocated_i )
    {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
        _single_thread_end;
        return 0;
    }
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_j = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].p == p )
        {   J_assert( i < E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].n );
            E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n = E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].n - i;
            E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].n = i;
            E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u = E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].u;
            E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p = (Pc)p + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_j ].u;
            P p_ = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
            E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( allocated_i, ~0 );
            E_mem_Q_blk_I_assert_on_return( __LINE__ );
            _single_thread_end;
            return p_;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    _single_thread_end;
    GV_(NXP); Gh(p); V();
}
_export
N
E_mem_Q_blk_W( P p
){  J_assert(p);
    if( U_R( E_base_S->E_flow_S_signal, exit_all )) //NDFN To sprawdzenie raczej umieszczać tylko w funkcjach wysokopoziomowych.
        return 0;
    _single_thread_begin;
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
        {   N n = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n;
            N u = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
            if(n)
            {   struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, n * u ))
                {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return ~0;
                }
            }
            E_mem_Q_blk_I_assert_on_return( __LINE__ );
            _single_thread_end;
            return 0;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    _single_thread_end;
    GV_(NXP); Gh(p); V();
}
//------------------------------------------------------------------------------
_internal
P
E_mem_Q_blk_I_add_( P p
, N n
, N *n_prepended
, N *n_appended
){  J_assert(n); // Puste użycie tej procedury.
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   Pc p_0 = 0;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            N l = n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   N l_1 = 0;
                p_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                struct E_mem_Q_blk_Z_free free_p_;
                N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
                if( ~max )
                {   struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
                    // Szukanie wolnego bloku przyległego od dołu.
                    N min = 0;
                    N max_0 = max;
                    N free_i = max / 2;
                    O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
                        {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                            {   l_1 = free_p[ free_i ].l;
                                if( l_1 > l )
                                    l_1 = l;
                                else if( l_1 < l )
                                    l_1 = E_simple_Z_n_I_align_down_to_v( l_1, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u );
                                l -= l_1;
                            }
                            break;
                        }
                        if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
                        {   if( free_i == min )
                                break;
                            max = free_i - 1;
                            free_i = max - ( free_i - min ) / 2;
                        }else
                        {   if( free_i == max )
                                break;
                            min = free_i + 1;
                            free_i = min + ( max - free_i ) / 2;
                        }
                    }
                    if( !l )
                    {   free_p[ free_i ].l -= l_1;
                        if( !free_p[ free_i ].l )
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                        *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                            #ifdef E_mem_Q_blk_C_debug
                        E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                            #endif
                        if( n_prepended )
                            *n_prepended = n;
                        if( n_appended )
                            *n_appended = 0;
                        return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1;
                    }
                    // Szukanie wolnego bloku przyległego od góry.
                    min = free_i;
                    max = max_0;
                    N free_j = ( max - min ) / 2 + min;
                    O{  if( p_0 + l_0 == free_p[ free_j ].p )
                        {   if( free_p[ free_j ].l < l )
                                break;
                            free_p[ free_j ].l -= l;
                            if( free_p[ free_j ].l )
                                free_p[ free_j ].p += l;
                            else
                                E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                            if( l_1 )
                            {   free_p[ free_i ].l -= l_1;
                                if( !free_p[ free_i ].l )
                                    E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                            }
                            E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                                #ifdef E_mem_Q_blk_C_debug
                            E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                            E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1 + l_0, l, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                                #endif
                            if( n_prepended )
                                *n_prepended = l_1 / E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                            if( n_appended )
                                *n_appended = l / E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                            return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1;
                        }
                        if( free_p[ free_j ].p > p_0 + l_0 )
                        {   if( free_j == min )
                                break;
                            max = free_j - 1;
                            free_j = max - ( free_j - min ) / 2;
                        }else
                        {   if( free_j == max )
                                break;
                            min = free_j + 1;
                            free_j = min + ( max - free_j ) / 2;
                        }
                    }
                    l += l_1; // Przywraca oryginalną wartość sprzed scalenia od dołu, skoro był blok przyległy od dołu, zabrakło do pełnej liczby od góry.
                }
            }
            P p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n + n
            , p_0
            , l_0
            , 0
            , ~0
            );
            if( !p_1 )
                return 0;
            *( P * )p = p_1;
                #ifdef E_mem_Q_blk_C_debug
            E_mem_Q_blk_P_fill_c( (Pc)p_1 + l_0, l, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            if( n_prepended )
                *n_prepended = 0;
            if( n_appended )
                *n_appended = n;
            return p_1;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
_internal
P
E_mem_Q_blk_I_prepend_append_( P p
, N n_prepend
, N n_append
){  J_assert( n_prepend && n_append ); // Puste użycie tej procedury.
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   Pc p_0 = 0;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   N l = ( n_prepend + n_append ) * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                N l_1 = 0;
                p_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                struct E_mem_Q_blk_Z_free free_p_;
                N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
                if( ~max )
                {   struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
                    // Szukanie wolnego bloku przyległego od dołu.
                    N min = 0;
                    N max_0 = max;
                    N free_i = max / 2;
                    O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
                        {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                            {   l_1 = free_p[ free_i ].l;
                                if( l_1 > l )
                                    l_1 = l;
                                else if( l_1 < l )
                                    l_1 = E_simple_Z_n_I_align_down_to_v( l_1, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u );
                                l -= l_1;
                            }
                            break;
                        }
                        if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
                        {   if( free_i == min )
                                break;
                            max = free_i - 1;
                            free_i = max - ( free_i - min ) / 2;
                        }else
                        {   if( free_i == max )
                                break;
                            min = free_i + 1;
                            free_i = min + ( max - free_i ) / 2;
                        }
                    }
                    if( l_1 )
                    {   // Szukanie wolnego bloku przyległego od góry.
                        min = free_i;
                        max = max_0;
                        N free_j = ( max - min ) / 2 + min;
                        O{  if( p_0 + l_0 == free_p[ free_j ].p )
                            {   if( free_p[ free_j ].l >= l )
                                {   E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n_prepend + n_append;
                                    if( l_1
                                    && free_p[ free_i ].l >= n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                                    && free_p[ free_j ].l >= n_append * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                                    )
                                    {   if( free_p[ free_j ].l )
                                            free_p[ free_j ].p += n_append * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                                        else
                                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                        free_p[ free_i ].l -= n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                                        if( !free_p[ free_i ].l )
                                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                        free_p[ free_j ].l -= n_append * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                                        *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                                        return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                                    }
                                    free_p[ free_j ].l -= l;
                                    if( free_p[ free_j ].l )
                                        free_p[ free_j ].p += l;
                                    else
                                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                    free_p[ free_i ].l -= l_1;
                                    if( !free_p[ free_i ].l )
                                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                    E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p - ( l_1 - n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                                    , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p
                                    , l_0
                                    );
                                    *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                                    return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1;
                                }
                                break;
                            }
                            if( free_p[ free_j ].p > p_0 + l_0 )
                            {   if( free_j == min )
                                    break;
                                max = free_j - 1;
                                free_j = max - ( free_j - min ) / 2;
                            }else
                            {   if( free_j == max )
                                    break;
                                min = free_j + 1;
                                free_j = min + ( max - free_j ) / 2;
                            }
                        }
                        l += l_1; // Przywraca oryginalną wartość sprzed scalenia od dołu, skoro był blok przyległy od dołu, zabrakło do pełnej liczby od góry.
                    }
                }
            }
            P p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n + n_prepend + n_append
            , p_0
            , l_0
            , n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , ~0
            );
            if( !p_1 )
                return 0;
            *( P * )p = p_1;
            return (Pc)p_1 + n_prepend * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
_internal
P
E_mem_Q_blk_I_append_( P p
, N n
, N align
){  J_assert(n); // Puste użycie tej procedury.
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   N l = n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            Pc p_0 = 0;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   N l_1 = 0;
                p_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                struct E_mem_Q_blk_Z_free free_p_;
                N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
                if( ~max )
                {   struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
                    // Szukanie wolnego bloku przyległego od góry.
                    N min = 0;
                    N free_i = max / 2;
                    O{  if( p_0 + l_0 == free_p[ free_i ].p )
                        {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                            {   l_1 = free_p[ free_i ].l;
                                if( l_1 > l )
                                    l_1 = l;
                                else if( l_1 < l )
                                    l_1 = E_simple_Z_n_I_align_down_to_v( l_1, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u );
                                l -= l_1;
                            }
                            break;
                        }
                        if( free_p[ free_i ].p > p_0 + l_0 )
                        {   if( free_i == min )
                                break;
                            max = free_i - 1;
                            free_i = max - ( free_i - min ) / 2;
                        }else
                        {   if( free_i == max )
                                break;
                            min = free_i + 1;
                            free_i = min + ( max - free_i ) / 2;
                        }
                    }
                    if( !l
                    && ( !~align
                      || E_simple_Z_p_T_aligned_to_v2( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, align )
                    ))
                    {   free_p[ free_i ].l -= l_1;
                        if( free_p[ free_i ].l )
                            free_p[ free_i ].p += l_1;
                        else
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                            #ifdef E_mem_Q_blk_C_debug
                        E_mem_Q_blk_P_fill_c( p_0 + l_0, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                            #endif
                        return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_0;
                    }
                    // Szukanie wolnego bloku przyległego od dołu.
                    min = 0;
                    max = free_i;
                    N free_j = max / 2;
                    if( ~align )
                        O{  if( free_p[ free_j ].p + free_p[ free_j ].l == p_0 )
                            {   Pc p_align = E_simple_Z_p_I_align_up_to_v2( free_p[ free_j ].p, align );
                                if( free_p[ free_j ].l >= ( p_align - free_p[ free_j ].p ) + l )
                                {   free_p[ free_j ].l = p_align - free_p[ free_j ].p;
                                    if( !free_p[ free_j ].l )
                                    {   E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                        free_i--;
                                    }
                                    if( l_1 )
                                    {   free_p[ free_i ].l -= l_1;
                                        free_p[ free_i ].l += ( p_0 - p_align ) - l;
                                        if( free_p[ free_i ].l )
                                        {   free_p[ free_i ].p += l_1;
                                            free_p[ free_i ].p -= ( p_0 - p_align ) - l;
                                        }else
                                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                    }else if(( p_0 - p_align ) - l )
                                    {   E_mem_Q_blk_Q_table_I_put_begin( &allocated_i );
                                        E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                                        struct E_mem_Q_blk_Z_free free_p_;
                                        if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p_align + l_0 + l, ( p_0 - p_align ) - l ))
                                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                                            E_mem_Q_blk_Q_table_I_put_end();
                                            E_mem_Q_blk_I_assert_on_return( __LINE__ );
                                        }else
                                        {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                                            E_mem_Q_blk_Q_table_I_put_end();
                                        }
                                    }
                                    E_mem_Q_blk_I_copy( p_align, p_0, l_0 );
                                        #ifdef E_mem_Q_blk_C_debug
                                    E_mem_Q_blk_P_fill_c( p_align + l_0, l + l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                                        #endif
                                    E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                                    *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p = p_align;
                                    return p_align + l_0;
                                }
                                break;
                            }
                            if( free_p[ free_j ].p + free_p[ free_j ].l > p_0 )
                            {   if( free_j == min )
                                    break;
                                max = free_j - 1;
                                free_j = max - ( free_j - min ) / 2;
                            }else
                            {   if( free_j == max )
                                    break;
                                min = free_j + 1;
                                free_j = min + ( max - free_j ) / 2;
                            }
                        }
                    else
                        O{  if( free_p[ free_j ].p + free_p[ free_j ].l == p_0 )
                            {   if( free_p[ free_j ].l >= l )
                                {   free_p[ free_j ].l -= l;
                                    if( !free_p[ free_j ].l )
                                    {   E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                        free_i--;
                                    }
                                    if( l_1 )
                                    {   free_p[ free_i ].l -= l_1;
                                        if( free_p[ free_i ].l )
                                            free_p[ free_i ].p += l_1;
                                        else
                                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                    }
                                    Pc p_1 = p_0 - l;
                                    E_mem_Q_blk_I_copy( p_1, p_0, l_0 );
                                    E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                                        #ifdef E_mem_Q_blk_C_debug
                                    E_mem_Q_blk_P_fill_c( p_1 + l_0, l + l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                                        #endif
                                    *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p = p_1;
                                    return p_1 + l_0;
                                }
                                break;
                            }
                            if( free_p[ free_j ].p + free_p[ free_j ].l > p_0 )
                            {   if( free_j == min )
                                    break;
                                max = free_j - 1;
                                free_j = max - ( free_j - min ) / 2;
                            }else
                            {   if( free_j == max )
                                    break;
                                min = free_j + 1;
                                free_j = min + ( max - free_j ) / 2;
                            }
                        }
                    l += l_1; // Przywraca oryginalną wartość sprzed scalenia od dołu, skoro był blok przyległy od dołu, a zabrakło do pełnej liczby od góry.
                }
            }
            P p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n + n
            , p_0
            , l_0
            , 0
            , align
            );
            if( !p_1 )
                return 0;
            *( P * )p = p_1;
                #ifdef E_mem_Q_blk_C_debug
            E_mem_Q_blk_P_fill_c( (Pc)p_1 + l_0, l, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            return (Pc)p_1 + l_0;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
_internal
P
E_mem_Q_blk_I_prepend_( P p
, N n
){  J_assert(n); // Puste użycie tej procedury.
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   N l = n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            Pc p_0 = 0;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   N l_1 = 0;
                p_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                struct E_mem_Q_blk_Z_free free_p_;
                N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
                if( ~max )
                {   struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
                    // Szukanie wolnego bloku przyległego od dołu.
                    N min = 0;
                    N max_0 = max;
                    N free_i = max / 2;
                    O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
                        {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                            {   l_1 = free_p[ free_i ].l;
                                if( l_1 > l )
                                    l_1 = l;
                                else if( l_1 < l )
                                    l_1 = E_simple_Z_n_I_align_down_to_v( l_1, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u );
                                l -= l_1;
                            }
                            break;
                        }
                        if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
                        {   if( free_i == min )
                                break;
                            max = free_i - 1;
                            free_i = max - ( free_i - min ) / 2;
                        }else
                        {   if( free_i == max )
                                break;
                            min = free_i + 1;
                            free_i = min + ( max - free_i ) / 2;
                        }
                    }
                    if( !l )
                    {   free_p[ free_i ].l -= l_1;
                        if( !free_p[ free_i ].l )
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                        *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                            #ifdef E_mem_Q_blk_C_debug
                        E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                            #endif
                        return p_0;
                    }
                    // Szukanie wolnego bloku przyległego od góry.
                    min = free_i;
                    max = max_0;
                    N free_j = ( max - min ) / 2 + min;
                    O{  if( p_0 + l_0 == free_p[ free_j ].p )
                        {   if( free_p[ free_j ].l >= l )
                            {   if( free_p[ free_j ].l -= l )
                                    free_p[ free_j ].p += l;
                                else
                                    E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                if( l_1 )
                                {   free_p[ free_i ].l -= l_1;
                                    if( !free_p[ free_i ].l )
                                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                }
                                E_mem_Q_blk_I_copy( p_0 + l, p_0, l_0 );
                                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                                if( l_1 )
                                    *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                                    #ifdef E_mem_Q_blk_C_debug
                                E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                                    #endif
                                return p_0 + l;
                            }
                            break;
                        }
                        if( free_p[ free_j ].p > p_0 + l_0 )
                        {   if( free_j == min )
                                break;
                            max = free_j - 1;
                            free_j = max - ( free_j - min ) / 2;
                        }else
                        {   if( free_j == max )
                                break;
                            min = free_j + 1;
                            free_j = min + ( max - free_j ) / 2;
                        }
                    }
                    l += l_1; // Przywraca oryginalną wartość sprzed scalenia od dołu, skoro był blok przyległy od dołu, a zabrakło do pełnej liczby od góry.
                }
            }
            P p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n + n
            , p_0
            , l_0
            , l
            , ~0
            );
            if( !p_1 )
                return 0;
                #ifdef E_mem_Q_blk_C_debug
            E_mem_Q_blk_P_fill_c( p_1, l, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            *( P * )p = p_1;
            return (Pc)p_1 + l;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
_internal
P
E_mem_Q_blk_I_insert_( P p
, N i
, N n
){  J_assert(n);
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   J_assert( i <= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n );
            Pc p_0 = 0;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
            {   N l = n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                N l_1 = 0;
                p_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
                struct E_mem_Q_blk_Z_free free_p_;
                N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_ );
                if( ~max )
                {   struct E_mem_Q_blk_Z_free *free_p = (P)E_base_S->E_mem_Q_blk_S_allocated[ E_base_S->E_mem_Q_blk_S_free_id ].p;
                    // Szukanie wolnego bloku przyległego od dołu.
                    N min = 0;
                    N max_0 = max;
                    N free_i = max / 2;
                    O{  if( free_p[ free_i ].p + free_p[ free_i ].l == p_0 )
                        {   if( free_p[ free_i ].l >= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u )
                            {   l_1 = free_p[ free_i ].l;
                                if( l_1 > l )
                                    l_1 = l;
                                else if( l_1 < l )
                                    l_1 = E_simple_Z_n_I_align_down_to_v( l_1, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u );
                                l -= l_1;
                            }
                            break;
                        }
                        if( free_p[ free_i ].p + free_p[ free_i ].l > p_0 )
                        {   if( free_i == min )
                                break;
                            max = free_i - 1;
                            free_i = max - ( free_i - min ) / 2;
                        }else
                        {   if( free_i == max )
                                break;
                            min = free_i + 1;
                            free_i = min + ( max - free_i ) / 2;
                        }
                    }
                    if( !l )
                    {   free_p[ free_i ].l -= l_1;
                        if( !free_p[ free_i ].l )
                            E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                        E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                        *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                        if(i)
                            E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p
                            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1
                            , i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                            );
                            #ifdef E_mem_Q_blk_C_debug
                        E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, l_1, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                            #endif
                        return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                    }
                    // Szukanie wolnego bloku przyległego od góry.
                    min = free_i;
                    max = max_0;
                    N free_j = ( max - min ) / 2 + min;
                    O{  if( p_0 + l_0 == free_p[ free_j ].p )
                        {   if( free_p[ free_j ].l >= l )
                            {   if( free_p[ free_j ].l -= l )
                                    free_p[ free_j ].p += l;
                                else
                                    E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_j );
                                if( l_1 )
                                {   free_p[ free_i ].l -= l_1;
                                    if( !free_p[ free_i ].l )
                                        E_mem_Q_blk_Q_sys_table_f_I_move_empty_entry( free_i );
                                    *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p -= l_1;
                                }
                                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n += n;
                                if( l_1 )
                                    E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p
                                    , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1
                                    , i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                                    );
                                E_mem_Q_blk_I_copy( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u + l
                                ,  E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + l_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                                , l_0 - i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                                );
                                    #ifdef E_mem_Q_blk_C_debug
                                E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, l_1 + l, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                                    #endif
                                return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                            }
                            break;
                        }
                        if( free_p[ free_j ].p > p_0 + l_0 )
                        {   if( free_j == min )
                                break;
                            max = free_j - 1;
                            free_j = max - ( free_j - min ) / 2;
                        }else
                        {   if( free_j == max )
                                break;
                            min = free_j + 1;
                            free_j = min + ( max - free_j ) / 2;
                        }
                    }
                }
            }
            P p_1 = E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
            , E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n + n
            , p_0
            , l_0
            , 0
            , ~0
            );
            if( !p_1 )
                return 0;
            //TODO Zrobić w “E_mem_Q_blk_Q_table_M_from_free_or_map” parametr przesuniecia dla ‘split’ i kopiowania tam od razu?
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
                E_mem_Q_blk_I_copy( (Pc)p_1 + ( i + n ) * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                , (Pc)p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                , l_0 - i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u
                );
                #ifdef E_mem_Q_blk_C_debug
            E_mem_Q_blk_P_fill_c( (Pc)p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
                #endif
            *( P * )p = p_1;
            return (Pc)p_1 + i * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
_internal
P
E_mem_Q_blk_I_remove_( P p
, N i
, N n
){  J_assert(n);
    struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == *( P * )p )
        {   J_assert( i + n <= E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n );
            N l = n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
            E_mem_Q_blk_Q_table_I_put_begin( &allocated_i );
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n == n ) // Usuwany cały blok.
            {   N allocated_i_sorted_pos;
                P p_ = E_mem_Q_blk_M_0( &allocated_i_sorted_pos );
                if( !p_ )
                    return 0;
                E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_
                , *( P * )p
                , l
                ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n = 0;
                *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p = p_;
                allocated_i = E_mem_Q_blk_Q_sys_table_a_I_sort_inserted( allocated_i, allocated_i_sorted_pos );
            }else if( i + n == E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n ) // Usuwane na końcu bloku.
            {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_
                , *( Pc * )p + l_0 - l
                , l
                ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n -= n;
            }else if( !i ) // Usuwane na początku bloku.
            {   E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                P p_ = *( P * )p;
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_
                , p_
                , l
                ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n -= n;
                *( P * )p = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p += l;
            }else // Usuwane w środku bloku.
            {   Pc p_0 = *( Pc * )p + ( i + n ) * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                E_mem_Q_blk_I_copy( p_0 - l
                , p_0
                , *( Pc * )p + l_0 - p_0
                );
                E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n -= n;
                E_mem_Q_blk_Q_table_I_put_before( E_base_S->E_mem_Q_blk_S_free_id );
                struct E_mem_Q_blk_Z_free free_p_;
                if( !~E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_
                , *( Pc * )p + l_0 - l
                , l
                ))
                {   E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
                    E_mem_Q_blk_Q_table_I_put_end();
                    return 0;
                }
                E_mem_Q_blk_Q_table_I_put_after( E_base_S->E_mem_Q_blk_S_free_id );
            }
            E_mem_Q_blk_Q_table_I_put_end();
            return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
        }
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > *( Pc * )p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return (P)~0;
}
//------------------------------------------------------------------------------
// Resize useing a boundary without memory move if possible.
// Gdy wynik jest niezerowy, to:
// • jeżeli “*n_appended”, to w wyniku jest adres nowego bloku przyległego od góry.
// • jeżeli “!*n_appended”, 〃 adres podanego bloku (przed którym dołączono blok przyległy od dołu).
// Te wartości nie są używane i mogą zostać zmienione.
_export
P
E_mem_Q_blk_I_add( P p
, N n
, N *n_prepended
, N *n_appended
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_add_( p, n, n_prepended, n_appended );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p_ )
    {   GV_(NXP); V();
    }
    return p_;
}
// Resize useing boundaries without memory move if possible.
// W wyniku podaje adres pierwotnego bloku (po ewentualnym przesunięciu).
_export
P
E_mem_Q_blk_I_prepend_append( P p
, N n_prepend
, N n_append
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_prepend_append_( p, n_prepend, n_append );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p_ )
    {   GV_(NXP); V();
    }
    return p_;
}
// Resize useing high boundary without memory move if possible.
// W wyniku podaje adres dołączonego bloku.
_export
P
E_mem_Q_blk_I_append( P p
, N n
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_append_( p, n, ~0 );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p_ )
    {   GV_(NXP); V();
    }
    return p_;
}
// Resize useing low boundary without memory move if possible.
// W wyniku podaje adres danych pierwotnego bloku.
_export
P
E_mem_Q_blk_I_prepend( P p
, N n
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_prepend_( p, n );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p_ )
    {   GV_(NXP); V();
    }
    return p_;
}
// Insert without memory move if possible.
// W wyniku podaje adres wstawionego bloku.
_export
P
E_mem_Q_blk_I_insert( P p
, N i
, N n
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_insert_( p, i, n );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p_ )
    {   GV_(NXP); Gh( p_ ); V();
    }
    return p_;
}
// Remove without memory move.
// W wyniku podaje nowy adres bloku (jak w “*( P * )p”).
_export
P
E_mem_Q_blk_I_remove( P p
, N i
, N n
){  _single_thread_begin;
    P p_ = E_mem_Q_blk_I_remove_( p, i, n );
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    _single_thread_end;
    if( !~(N)p )
    {   GV_(NXP); V();
    }
    return p_;
}
//==============================================================================
    #ifdef C_to_libs_C_replace_c_alloc
_export
size_t
        #if defined( __FreeBSD__ )
malloc_usable_size( const void *p
        #else
malloc_usable_size( P p
        #endif
){  Da_();
    if( !p )
        return 0;
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( !errno_ )
        #endif
    {   struct E_mem_Q_blk_Z_allocated allocated_p;
        N min = 0;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
        N allocated_i = max / 2;
        O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
            {   N l = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                _single_thread_end;
                return l;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
            {   if( allocated_i == min )
                    break;
                max = allocated_i - 1;
                allocated_i = max - ( allocated_i - min ) / 2;
            }else
            {   if( allocated_i == max )
                    break;
                min = allocated_i + 1;
                allocated_i = min + ( max - allocated_i ) / 2;
            }
        }
        _single_thread_end;
        return E_base_S->E_mem_Q_blk_I_libc_malloc_usable_size ? ( *E_base_S->E_mem_Q_blk_I_libc_malloc_usable_size )(p) : 0;
    }
    return 0;
}
//------------------------------------------------------------------------------
_internal
__attribute__ (( __malloc__ ))
P
E_mem_Q_blk_M_calloc(
  N u
, N n
, N align
){  struct E_mem_Q_blk_Z_allocated allocated_p;
    N allocated_i = E_mem_Q_blk_Q_sys_table_M_new_id( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p, (Pc)&allocated_p.n - (Pc)&allocated_p, 0, 0 );
    if( !~allocated_i )
    {   E_mem_Q_blk_I_assert_on_return( __LINE__ );
        _single_thread_end;
        return 0;
    }
    if( !E_mem_Q_blk_Q_table_M_from_free_or_map( &allocated_i, u, n, 0, 0, 0, align ))
    {   E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
        E_mem_Q_blk_I_assert_on_return( __LINE__ );
        _single_thread_end;
        return 0;
    }
        #ifdef E_mem_Q_blk_C_debug
    if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n )
        E_mem_Q_blk_P_fill_c( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p, E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u, 0xa5 ); //TODO Procedura usuwająca zerowanie nowej pamięci na czas usuwania zmiennych globalnych i testów.
        #endif
    E_mem_Q_blk_I_assert_on_return( __LINE__ );
    return E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p;
}
//------------------------------------------------------------------------------
_export
__attribute__ (( __malloc__(free) ))
P
aligned_alloc(
  size_t align
, size_t size
){  Da_();
    if( !E_simple_Z_n_T_power_2(align) )
    {   _errno = EINVAL;
        return 0;
    }
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( errno_ )
        return E_base_S->E_mem_Q_blk_I_libc_aligned_alloc ? ( *E_base_S->E_mem_Q_blk_I_libc_aligned_alloc )( align, size ) : 0;
        #endif
    P p_ = E_mem_Q_blk_M_calloc( 1, size, align );
    _single_thread_end;
    if( !p_ )
        _errno = ENOMEM;
    return p_;
}
_export
int
posix_memalign( P *p
, size_t align
, size_t size
){  Da_();
    if( !E_simple_Z_n_T_power_2(align)
    || align % sizeof(P)
    )
        return EINVAL;
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( errno_ )
        return E_base_S->E_mem_Q_blk_I_libc_posix_memalign ? ( *E_base_S->E_mem_Q_blk_I_libc_posix_memalign )( p, align, size ) : ( *p = 0, 0 );
        #endif
    P p_ = E_mem_Q_blk_M_calloc( 1, size, align );
    _single_thread_end;
    if( !p_ )
        return ENOMEM;
    *p = p_;
    return 0;
}
_export
__attribute__ (( __malloc__(free) ))
P
malloc( size_t l
){  Da_();
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( errno_ )
        return E_base_S->E_mem_Q_blk_I_libc_malloc ? ( *E_base_S->E_mem_Q_blk_I_libc_malloc )(l) : 0;
        #endif
    if( !l ) // Przydzielenie minimalnego rozmiaru dla rozmiaru zerowego.
        l = E_mem_Q_blk_S_align_to_all;
    P p = E_mem_Q_blk_M_calloc( 1, l, E_mem_Q_blk_S_align_to_all );
    _single_thread_end;
    if( !p )
        _errno = ENOMEM;
    return p;
}
_export
__attribute__ (( __malloc__(free) ))
P
calloc( size_t n
, size_t u
){  Da_();
    if( E_simple_T_multiply_overflow( n, u ))
    {   _errno = ENOMEM;
        return 0;
    }
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( errno_ )
        return E_base_S->E_mem_Q_blk_I_libc_calloc ? ( *E_base_S->E_mem_Q_blk_I_libc_calloc )( n, u ) : 0;
        #endif
    P p = E_mem_Q_blk_M_calloc( 1, n * u, E_mem_Q_blk_S_align_to_all );
    _single_thread_end;
    if(p)
        _0( p, n * u );
    else
        _errno = ENOMEM;
    return p;
}
_export
__attribute__ (( __malloc__(free) ))
P
realloc( P p
, size_t l
){  Da_();
    if( !p )
        return malloc(l);
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( !errno_ )
        #endif
    {   struct E_mem_Q_blk_Z_allocated allocated_p;
        N min = 0;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
        N allocated_i = max / 2;
        O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
            {   N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                if( !l )
                {   N n_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n;
                    E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
                    if( n_0 )
                    {   struct E_mem_Q_blk_Z_free free_p_;
                        E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l_0 );
                    }
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return 0;
                }
                if( l > l_0 )
                {   P p_ = E_mem_Q_blk_I_append_( &p, l - l_0, E_mem_Q_blk_S_align_to_all );
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    if( p_ )
                        p_ = p;
                    else
                        _errno = ENOMEM;
                    return p_;
                }
                if( l < l_0 )
                {   P p_ = E_mem_Q_blk_I_remove_( &p, l, l_0 - l );
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return p_;
                }
                E_mem_Q_blk_I_assert_on_return( __LINE__ );
                _single_thread_end;
                return p;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
            {   if( allocated_i == min )
                    break;
                max = allocated_i - 1;
                allocated_i = max - ( allocated_i - min ) / 2;
            }else
            {   if( allocated_i == max )
                    break;
                min = allocated_i + 1;
                allocated_i = min + ( max - allocated_i ) / 2;
            }
        }
        _single_thread_end;
        return E_base_S->E_mem_Q_blk_I_libc_realloc ? ( *E_base_S->E_mem_Q_blk_I_libc_realloc )( p, l ) : 0;
    }
    return 0;
}
_export
__attribute__ (( __malloc__(free) ))
P
reallocarray( P p
, size_t n
, size_t u
){  Da_();
    if( E_simple_T_multiply_overflow( n, u ))
    {   _errno = ENOMEM;
        return 0;
    }
    N l = n * u;
    if( !p )
        return malloc(l);
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( !errno_ )
        #endif
    {   struct E_mem_Q_blk_Z_allocated allocated_p;
        N min = 0;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
        N allocated_i = max / 2;
        O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
            {   N l_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n * E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                if( !l )
                {   N n_0 = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n;
                    E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
                    if( n_0 )
                    {   struct E_mem_Q_blk_Z_free free_p_;
                        E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, l_0 );
                    }
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return 0;
                }
                if( l > l_0 )
                {   P p_ = E_mem_Q_blk_I_append_( &p, l - l_0, E_mem_Q_blk_S_align_to_all );
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    if( p_ )
                        p_ = p;
                    else
                        _errno = ENOMEM;
                    return p_;
                }
                if( l < l_0 )
                {   P p_ = E_mem_Q_blk_I_remove_( &p, l, l_0 - l );
                    E_mem_Q_blk_I_assert_on_return( __LINE__ );
                    _single_thread_end;
                    return p_;
                }
                E_mem_Q_blk_I_assert_on_return( __LINE__ );
                _single_thread_end;
                return p;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
            {   if( allocated_i == min )
                    break;
                max = allocated_i - 1;
                allocated_i = max - ( allocated_i - min ) / 2;
            }else
            {   if( allocated_i == max )
                    break;
                min = allocated_i + 1;
                allocated_i = min + ( max - allocated_i ) / 2;
            }
        }
        _single_thread_end;
        return E_base_S->E_mem_Q_blk_I_libc_reallocarray ? ( *E_base_S->E_mem_Q_blk_I_libc_reallocarray )( p, n, u ) : 0;
    }
    return 0;
}
_export
void
free( P p
){  Da_();
    if( !p ) // Funkcja zerowego adresu, taka jak w oryginalnym “free”.
        return;
        #ifdef C_pthreads
    int errno_ = pthread_mutex_trylock( &E_base_S->E_mem_Q_blk_S_threads_sync_mutex );
    if( errno_
    && errno_ != EBUSY
    )
    {   _errno = errno_;
        Ve();
        V();
    }
    if( !errno_ )
        #endif
    {   struct E_mem_Q_blk_Z_allocated allocated_p;
        N min = 0;
        N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
        N allocated_i = max / 2;
        O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
            {   N n = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].n;
                N u = E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].u;
                E_mem_Q_blk_Q_sys_table_a_I_move_empty_entry( allocated_i );
                if(n)
                {   struct E_mem_Q_blk_Z_free free_p_;
                    E_mem_Q_blk_Q_sys_table_mf_P_put( E_base_S->E_mem_Q_blk_S_free_id, (Pc)&free_p_.p - (Pc)&free_p_, (Pc)&free_p_.l - (Pc)&free_p_, p, n * u );
                }
                E_mem_Q_blk_I_assert_on_return( __LINE__ );
                _single_thread_end;
                return;
            }
            if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
            {   if( allocated_i == min )
                    break;
                max = allocated_i - 1;
                allocated_i = max - ( allocated_i - min ) / 2;
            }else
            {   if( allocated_i == max )
                    break;
                min = allocated_i + 1;
                allocated_i = min + ( max - allocated_i ) / 2;
            }
        }
        _single_thread_end;
        if( E_base_S->E_mem_Q_blk_I_libc_free )
            ( *E_base_S->E_mem_Q_blk_I_libc_free )(p);
    }
}
    #endif
/******************************************************************************/
_export
B
E_mem_Q_blk_T( P p
){  struct E_mem_Q_blk_Z_allocated allocated_p;
    N min = 0;
    N max = E_mem_Q_blk_Q_sys_table_R_last( E_base_S->E_mem_Q_blk_S_allocated_id, (Pc)&allocated_p.p - (Pc)&allocated_p );
    N allocated_i = max / 2;
    O{  if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p == p )
            return yes;
        if( E_base_S->E_mem_Q_blk_S_allocated[ allocated_i ].p > (Pc)p )
        {   if( allocated_i == min )
                break;
            max = allocated_i - 1;
            allocated_i = max - ( allocated_i - min ) / 2;
        }else
        {   if( allocated_i == max )
                break;
            min = allocated_i + 1;
            allocated_i = min + ( max - allocated_i ) / 2;
        }
    }
    return no;
}
